{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuner of Text Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipynb\n",
    "from ipynb.fs.defs.data_collect_preprocessing1 import get_x_y_preprocessed\n",
    "from ipynb.fs.defs.data_collect_preprocessing1 import get_one_hot\n",
    "from ipynb.fs.defs.data_collect_preprocessing1 import CATEGORIES\n",
    "from ipynb.fs.defs.data_collect_preprocessing1 import preprocess_text\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import InputLayer, Input, Dense, Embedding, Flatten, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, GRU, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# from tqdm import tqdm\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy import stats\n",
    "# pip install -q -U keras-tuner\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sport', 'politics', 'economics', 'psychology', 'philosophy', 'literature', 'physics']\n"
     ]
    }
   ],
   "source": [
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36acca3441bc4397ae86f287eb68a158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3341.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_rec, y_rec = get_x_y_preprocessed(\"dataset_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type x_rec:  <class 'list'>\n",
      "type y_rec:  <class 'tuple'>\n",
      "x_rec:  3341\n",
      "y_rec:  (3341, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"type x_rec: \", type(x_rec))\n",
    "print(\"type y_rec: \", type(y_rec.shape))\n",
    "print(\"x_rec: \", len(x_rec))\n",
    "print(\"y_rec: \", y_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive', 'relationship', 'increasing', 'point', 'f', ',', 'beyond', 'income', 'effect', 'dominates', 'substitution', 'effect', 'individual', 'starts', 'reduce', 'number', 'labour', 'hours', 'supplies', '(point', 'g)', 'wage', 'increases', ';', 'words', ',', 'wage', 'elasticity', 'negativethe', 'direction', 'slope', 'may', 'change', 'individuals', ',', 'labour', 'supply', 'curve', 'different', 'different', 'individualsother', 'variables', 'affect', 'labour', 'supply', 'decision', ',', 'readily', 'incorporated', 'model', ',', 'include', 'taxation', ',', 'welfare', ',', 'work', 'environment', ',', 'income', 'signal', 'ability', 'social', 'contribution']\n",
      "[0. 0. 1. 0. 0. 0. 0.]\n",
      "economics\n"
     ]
    }
   ],
   "source": [
    "print(x_rec[1000])\n",
    "print(y_rec[1000])\n",
    "print(CATEGORIES[np.argmax(y_rec[1000])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "NUM_WORDS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
    "print(tokenizer.num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"literature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3341\n"
     ]
    }
   ],
   "source": [
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_seq = [len(s)  for s in sequences]\n",
    "len_seq = np.array(len_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.hist(len_seq, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min: 23\n",
      "mean: 54.03023046991919\n",
      "max 483\n",
      "median 50.0\n",
      "mode: ModeResult(mode=array([42]), count=array([143]))\n",
      "sigma: 24.65488791236795\n",
      "75 percentile: 58.0\n",
      "num over 75 percentile: 773\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"min:\", len_seq.min())\n",
    "print(\"mean:\", len_seq.mean())\n",
    "print(\"max\", len_seq.max())\n",
    "print(\"median\", np.median(len_seq))\n",
    "print(\"mode:\", stats.mode(len_seq))\n",
    "print(\"sigma:\", np.std(len_seq))\n",
    "\n",
    "PERCENTILE = 75\n",
    "print(PERCENTILE, \"percentile:\", np.percentile(len_seq, PERCENTILE))\n",
    "print(\"num over\", PERCENTILE, \"percentile:\", np.count_nonzero(len_seq > np.percentile(len_seq, PERCENTILE))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentence over SENTENCE_LENGTH: 655\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_LENGTH = 60\n",
    "print(\"Num sentence over SENTENCE_LENGTH:\", np.count_nonzero(len_seq > SENTENCE_LENGTH)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num_fix = pad_sequences(sequences, maxlen=SENTENCE_LENGTH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 266,  539,  678,  116,  191,    1,  789,  485,  271, 5962, 3772,\n",
       "        271,   91, 2282, 1005,   51,  202, 2267, 7718,  625, 1015,    7,\n",
       "       1012,    1,  625, 2521,  516, 3740,   13,  175,  268,    1,  202,\n",
       "        508, 1363,   45,   45, 1067,  764,  202,  508,  351,    1, 3750,\n",
       "       2295,   89,    1,   31, 6023,    1, 2349,    1,   16,  403,    1,\n",
       "        485, 3055,  437,   10, 1569])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num_fix[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_num_fix, y_rec, test_size=0.20, random_state=42)  # dividiamo il dataset lasciando una parte (0.2 quindi 20%) per la validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  2672\n",
      "y_train:  (2672, 7)\n",
      "X_test:  669\n",
      "y_test:  (669, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \", len(X_train))\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", len(X_test))\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  embedding glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_EMBEDDING_PATH = \"C:\\\\Users\\\\lpdepersiis\\\\PycharmProjects\\\\autoencoderNlp\\\\embedding\\\\en\\\\glove\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_matrix():\n",
    "    \"\"\"\n",
    "    Questa funzione ci serve per crearci un dizionario avente come indice la parola e come valore il vettore dell'embedding corrispondente\n",
    "    \"\"\"\n",
    "    word_matrix = {}\n",
    "    with open(MY_EMBEDDING_PATH + 'glove.6B.100d.txt', 'r', encoding='UTF-8') as file_emb:\n",
    "        lines = [line for line in file_emb]\n",
    "        for row in tqdm(lines, total=len(lines)): # leggo ogni riga del file di testo contenente l'embedding\n",
    "            row = row.split() # la divido nei suoi elementi\n",
    "            word_matrix[row[0]] = np.array(row[1:], dtype='float32') # il primo è la parola e sarà l'indice di questa voce, gli altri andranno a formare il vettore \n",
    "    return word_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbbe09b3e434266a6451804dd178bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=400000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "word_matrix = get_word_matrix()\n",
    "\n",
    "print(len(word_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(embeddings_index, word_index, dim_embeddings=EMBEDDING_DIM, num_words=NUM_WORDS):\n",
    "    \"\"\"\n",
    "    Tramite questa funzione creiamo una matrice in cui le righe siano nello stesso ordine dell'indice ottenuto dal tokenizer \n",
    "    e che contenga solo i vettori relativi alle parole in esso contenute\n",
    "    \n",
    "    :param embeddings_index: il dizionario, ottenuto dall'embedding, avente le parole come indice ed i vettori come valore\n",
    "    :param word_index:  il dizionario ottenuto dal tokenizer avente come indice la parola e come valore il suo indice\n",
    "    :param dim_embeddings: la lunghezza dei vettori dell'embedding che stiamo utilizzando\n",
    "    :param num_words: il numero di parole più frequenti da utilizzare\n",
    "    :return: la matrice dei vettori dell'embedding ordinata come il nostro indice\n",
    "\n",
    "    \"\"\"\n",
    "    embedding_matrix = np.zeros((num_words + 1, dim_embeddings))  # creiamo la matrice di zeri avente tante righe quante sono le parole (più una) e tante colonne quante sono quelle dei vettori\n",
    "    error_word = []\n",
    "    for word in tqdm(word_index.keys(), total=num_words):  # Scorriamo le parole dell'indice del tokenizer\n",
    "        if word_index[word] >= num_words:\n",
    "            break\n",
    "        embedding_vector = embeddings_index.get(word)  # estraiamo il vettore corrispondente\n",
    "        if embedding_vector is not None:  # verifichiamo che esista (anche se il nostro dizionario è più piccolo di quello dell'embedding potrebbe contenere parolo non presenti in esso)\n",
    "            # se la parola è presente andiamo avanti (se non è presente, in corrispondenza di questo indice, rimarrà il vettore formato da zeri)\n",
    "            embedding_matrix[word_index[word]] = embedding_vector  # impostiamo nella matrice quella riga con il vettore corrispondente alla parola\n",
    "        else:\n",
    "            error_word.append(word)\n",
    "    \n",
    "    print(error_word)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58626ffd2d4dddae55aa389a80f010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['', '{\\\\displaystyle', '\"the', '⋅', '(or', '{\\\\frac', '−', '(the', '\\\\mathbf', '(e', \"one's\", '(such', '∫', '{x}', '(in', '\\\\cdot', \"women's\", '{f}', '(see', '˙', '{v}', '\\\\psi', '{\\\\mathbf', \"master's\", '\\\\int', '(i', '\"a', '(also', \"world's\", '(and', '(a', '(as', \"individual's\", \"keynes's\", '{\\\\dot', 'ℏ', \"country's\", 'pressisbn', '\\t\\t', '}}', '{d}', '(including', 'bce)', \"newton's\", '(which', 'left–right', \"school's\", \"aristotle's\", \"lse's\", '(sometimes', \"people's\", 'mph)', 'csikszentmihályi', \"party's\", \"eysenck's\", '⟨', '⟩', \"bbc's\", '(from', '(who', '(for', '016/b978-0-08-097086-8', '\\\\delta', '(1', \"men's\", 'ccording', \"plato's\", \"child's\", 'vaiśeṣika', '{r}', 'work–energy', \"sport's\", '\"political', '(with', 'bc)', 'nyāya', 'century)', \"nobel's\", '}}\\\\cdot', '\\\\phi', '\\u2061', \"bachelor's\", '(us)', '→', '{\\\\omega', '_{t_{1}}^{t_{2}}\\\\mathbf', '(2', '(often', '\"to', \"person's\", \"kahn's\", 'mīmāṃsā', 'literature\"', 'a}', '{t}', '(usually', 'force)', 'centurythe', '\"new', '\"for', '\"what', 'itthe', \"organism's\", 'volutionary', 'gestaltists', 'sovatsky', 'pyrrhonism', '{e}', 'd\\\\mathbf', '{s}', '(to', '300+', '(on', 'mi)', 'below)', 'psychologythe', '(but', '(2001)', '(though', '5%', \"student's\", \"piaget's\", 'psychologyin', 'non-kin', 'csíkszentmihályi', 'autotelic', 'prägnanz', \"kant's\", 'philosophy\"', \"socrates'\", '(c', 'nāstika', 'philosophy)', '{\\\\vec', '{\\\\mathcal', '{d\\\\mathbf', '_{c}\\\\mathbf', 'p(t)', '∂', 'worldthe', 'ps)', '(typically', '(known', '(formerly', '(both', \"children's\", '\"human', \"earth's\", 'olitical', '\"we', '(2013)', 'theory\"', 'economythe', 'edsthe', 'everal', '\"in', '(eds', \"keynes'\", 'theory)', \"students'\", 'philosophythe', \"psychology's\", 'age\"', \"humans'\", 'psychology\"international', 'āstika', '}}}', 't}', \"object's\", '_{\\\\mathrm', '\\\\mathrm', '-{\\\\frac', '{\\\\hbar', 'b}', 'yearsthe', 'lb)', \"company's\", '(not', '×', '(2008)', '\\u200a3\\u200a', \"worker's\", 'science\"', '(by', \"government's\", 'others)', '(ed', \"lincoln's\", \"'as\", 'thought\"', 'economics)', '(economic', '\"all', '\"i', '(like', \"firm's\", '\"how', \"man's\", '\"cognitive', 'world\"', 'developmentthe', 'adaptedness', '(2005)', \"author's\", 'lukoff', 'isced', 'pratyakṣa', 'anumāṇa', '(perception)', 'sub-school', \"einstein's\", '\"hindu\"', '(since', '\"unorthodox\"', 'nobel)', '0)', 'h}', 'physics\"', \"planck's\", '\\\\langle', '{\\\\hat', 'x(t)', '_{t_{1}}^{t_{2}}{\\\\frac', 'm\\\\int', 'inverdale', 'only)', \"university's\", 'statesthe', '(except', 'm)', '\"not', '\"national', '\\u200a13\\u200a', 'societythe', '\\u200a', '(1996)', '(1)', '\"left\"', 'religionism', '\"one', '(where', '(help)', \"president's\", 'etcthe', '50%', \"candidate's\", 'state)', \"marx's\", 'aggregative', \"king's\", '\"if', 's\\u202f(y\\u202f)', '10%', '\"that', '(4)', '(2)', '(2014–15', 'psychology\"', '(example', '(called', \"infant's\", 'principle)', '(2004)', \"freud's\", '(now', 'prepersonal', '\"spiritual', 'german)', 'darśana', 'ce)', 'pramāṇa', '(inference)', 'literaturethe', \"russell's\", 'textsthe', \"husserl's\", '(1969)', 'literaturenew', 'direction\"', 'mankind\"', 'prize-awarding', '0}', \"kirchhoff's\", '_{\\\\delta', '{avg}', '{\\\\delta', '{\\\\boldsymbol', '\\\\rangle', '}\\\\psi', '{\\\\sqrt', '}}dt', '-\\\\int', '+\\\\mathbf', 'timein', 'yearsin', \"britain's\", 'extracommentary', '2024)', 'sports)', 'quad-turbocharged', '(2019)', 'mansory', '(0', '(7', \"athletes'\", \"magazine's\", '\"sport\"', '(an', '(founded', 'eventsthe', '(later', '(russian', '\"has', '\\u200a165\\u200a', 'governmentin', 'lawthe', \"today's\", '\"as', '(2011)', 'science)', 'tough-mindedness', '(1995)', 'governmentthe', 'revolutionthe', '20%', 'university)', '\"politics', 'things\"', '(\"the', '2)', '3)', 'psychology)', 'bar-pressing', 'respectivelythe', \"humanity's\", 'stage/degree', 'whatiseconomy', 'respending', '\"it', 'i\\u202f(r\\u202f)', '(chapter', 'a)', 'neo-keynesian', '(c)', '\\\\over', 'high-ability', '(1954)', '(when', 'revolution\"', \"brain's\", '(especially', 'fuzzy-trace', '3–5', '\"more', \"others'\", \"darwin's\", '(2006)', 'coalitional', 'sssm', '30%', '\"too', \"csíkszentmihályi's\", 'owever', 'gestalt-qualität', \"wertheimer's\", '(a)', 'multistability', 'energythe', 'cognitive-behavior', '(2010)', '\"transpersonal\"', \"wilber's\", 'non-dualism', '(1998)', '(d', 'sciences)', 'degree)', 'ājīvika', 'pāśupata', 'pratyabhijña', 'vedantins', 'pashupata', 'trika', 'upamāṇa', 'puruṣa', 'selfs', 'śabda', 'world)', 'insentient', '(no', \"'love\", '(3rd', 'physika', 'thought)', 'cyrenaicism', 'centuries)', '19th-', \"'the\", 'dhárma', '\"orthodox\"', 'shavism', 'karma)', '(1472–1529)', 'teotl', '(active', 'philosophyit', \"qur'an\", '(born', 'sigea', '\"literature\"', '\"erotische', 'literatur\"', 'schweikle', \"academy's\", 'frostenson', '(1848)', 'zepetnek', '(measured', \"maxwell's\", '1⁄2', '(t)', \"rutherford's\", 'nitrogen-14', '\\\\alpha', '1}', 'nonthermal', 'ϵ', '\\\\tau', 'p_{\\\\lambda', '\\\\hbar', '\\\\sigma', '{\\\\partial', '⊗', '{\\\\tfrac', '\\\\qquad', '\"upper\"', '{\\\\theta', '}}\\\\mathbf', '{a}', '{m}{2}}\\\\int', 'm{\\\\ddot', '{m}{2}}{\\\\dot', '{m}{2}}v^{2}(t_{2})-{\\\\frac', '{m}{2}}v^{2}(t_{1})', 'co-commentators', \"queen's\", 'ollowing', '2016the', '(2016–present)', 'sportsthe', \"wilson's\", 'england)', '5)', '(wales', 'livereports', '2020)', \"america's\", '25%', 'communitythe', 'n⋅m', '0–200', '(0–124', '0–300', '(0–186', '(12', '(2020)', 'forcethe', 'centodieci', 'ehra-lessien', '(black', 'body)', 'madethe', '(5', 'statesin', 'years)', 'universitythe', \"rower's\", 'races)', '(due', '(6', 'cox)', 'womenin', 'arms)', 'booksisbn', '(refer', 'old)', 'competition)', 'bcthe', 'athleticsthe', '(first', 'othersthe', '(based', '(1981)', 'more)', '(excluding', \"china's\", 'game\"', '(commonly', 'themthe', 'party\"', '\\u200a510\\u200a', 'partythe', \"parties'\", '\\u200a163–178\\u200a', \"duverger's\", 'example)', \"india's\", 'odern', 'phenomenain', '(2012)', 'scienceoxford', 'beckisbn', '2014retrieved', 'liberalism)', 'left\"', \"ferguson's\", '(written', \"researcher's\", \"inglehart's\", \"states'\", 'policy)', 'countries)', '(having', '(positive', '(οἶκος', 'oikos)', 'nature\"', 'government)', 'theoryfor', 'states)', 'people)', 'governmentsthe', 'india)', 'minister)', 'statethe', 'levelthe', '1%', \"society's\", 'gilens', '(9th', '(3', '(14th', 'politiká', '\"who', '\"social', 'otherssome', 'routledgeisbn', \"thaler's\", 'ehavioral', '\"good', \"becker's\", '(most', '\"economy\"', \"bell's\", 'product)', 'economy)', '\"first', '$1000', \"samuelson's\", '\"investment\"', 'demand\"', 'r\\u202f', '\"this', 'r̂\\u202f', '(it', '(y', 'trade)', '2007–08', 'synthesis\"', 'flowin', \"employer's\", '(point', 'effectthe', 'above)', 'journal}}', '|journal', '2020/21', '2015–16', '\"great', 'schoolit', '2016)', 'yearthe', 'ecent', '(alumni)', 'unobservables', 'it)', '1987)', 'post-conventional', 'life)', 'species-typical', 'ocial', 'psychologyhowever', \"mother's\", \"infants'\", '(this', '\"no', 'demandingness', 'domain-general', \"hamilton's\", '(1964)', '\"evolutionary', \"parents'\", 'adaptationist', '\"mental', 'nature)', \"woman's\", '1989)', '(1989)', 'curlie', 'hyperfocus', 'daythe', '(if', 'roups', \"player's\", 'hedonic-motivation', 'hmsam', 'work\"', 'gestaltism', \"mach's\", '\"gestalt\"', '\"there', '(what', 'field)', 'motion)', '\"soul\"', 'man\"', 'psychologia', '\"natural', '\"is', 'individualin', \"kuhn's\", 'thoughtthe', \"individuals'\", 'timeit', 'researchthe', \"study's\", \"participants'\", 'timethe', 'metascience', 'researchin', '$1', 'ssues', 'psychospiritual', 'consciousnessthe', 'society\"', 'boucovolas', 'holotropic', '(3)', 'perennialism', \"ferrer's\", '(other', '(california)', 'grof’s', '(uk)', '(ancient', '\"an', 'maroneia', '(2009)', '\"dr', '\"phd\"', '\"phd', 'law)', 'medicine)', 'awardedin', '(without', 'tohtori', \"magister's\", 'filosofie', \"licentiate's\", 'доктор', '6%', 'nauk)', '2005)', '(nāstika)', '(eternal', '(self)', 'arthāpatti', 'anupalabdi', 'schoolthe', '(comparison', 'analogy)', '(word', 'knowledgethis', 'viśiṣṭādvaita', 'brahman)', 'antirealists', \"homer's\", '(1966)', 'physicsin', '(latin', \"nature'\", 'staugustine', 'enlightenment)', 'interpretationsthe', '(along', 'buddhismthe', '(6th', '\"critical', 'mutazilite', '(power)', \"mill's\", '\"liberty', \"hegel's\", 'vaihinger', \"vaihinger's\", 'cyrenaics', 'non-evident', '(more', 'spinozism', \"girl's\", 'sado-masochism', '(1907)', 'fictionthe', 'kronhausen', 'erotischen', 'weltliteratur', 'literature)', '\"grey', 'proto-science', 'ad)', '\"oral', 'idealisk', '\"any', 'prizethe', 'designthe', 'karlfeldt', 'espmark', 'danius', '(1847)', \"dickens'\", \"victoria's\", 'tötösy', 'literaturelondon', \"material's\", \"body's\", 'antineutron', 'charge)', 'electrons)', \"substance's\", '\\\\scriptstyle', 'c}', 'nuclei)', '(si)', 'mechanics)', 'wave–particle', \"yukawa's\", 'neutrons)', 'physics)', 'states)its', 'quasineutral', '\"plasma', 'n_{i}}', '\\\\nu', 'filamentation', 'defocusing', '{dw}{dt}}', '}{dt}}', 't}\\\\mathbf', 'p_{\\\\mathrm', 't}}}', '{\\\\mathrm', '\\\\epsilon', '{pulse}', '{c}', '^{2}}', '|\\\\langle', '{\\\\lambda', '{\\\\langle', 'i\\\\hbar', 'e^{-iht/\\\\hbar', '^{2}}}', '}{2}}', '_{a}}', '_{b}}', '_{a}\\\\otimes', '{1}{\\\\sqrt', '(x', '{\\\\psi', '}}(k', 'k}', '\\\\ldots', '{m\\\\omega', 'mach–zehnder', '\"lower\"', '_{l}', '|^{2}', 'bpb\\\\psi', 'x(t1)', 'x(t2)', '}}\\\\', '_{\\\\mathbf', '(t_{1})}^{\\\\mathbf', '∇', 'u}{\\\\partial', '{gmm}{r^{3}}}\\\\mathbf', '{\\\\textstyle', '\\\\quad', '_{i}-\\\\mathbf', '∑', '_{i', 'onlinethe', 'networksthe', \"england's\", '2015the', '2024the', 'twothe', 'sub-license', 'runthe', '2014–2016', '(primarily', '2018–19', 'eventa', '2012the', '(until', '(live', '2025wales', 'matchesbbc', 'scotlandcommentary', 'servicecommentary', 'livecommentary', '(shared', '(uk', 'union)', 'servicesa', 'carthe', '(8', 'lb⋅ft)', '0–100', '(0–62', \"chiron's\", '€2', '(2018)', 'colourthe', 'légendes', '(2021)', '(9', '\"la', '(similar', 'naturethe', '0–400–0', '(0–249–0', \"germany's\", 'total)', 'oarlocks', 'harvard–yale', 'fatherin', '(following', 'rowthe', 'championshipsthe', 'oarlock', 'chestthe', 'material)', '(colloquially', 'ft)', '(4', '(depending', \"cambridge's\", '(160', '(legs', 'bodyworld', '\"sports', 'depth\"', '(new', '(espn)', 'athletics)', 'yearbook”', '\"they', 'techniquesthe', 'pool)', 'ompetitors', '(identified', 'rules)', '‘signal-pliers’', 'marifé', 'russiasnow', '(international', '(cmas', '04/09/2012', 'termthe', '(although', 'sport)', '(iaaf)', 'skyrunning', 'modelthe', 'wellthe', 'americathe', \"year's\", '(small', 'disability)', 'спорт', 'sportshowever', '(through', 'non-participants', '\"sports\"', 'incentivised', 'resultsa', 'religionthe', 'islands)', 'microcontinental', 'oceanthe', 'mainland)', 'stpetersburg', 'centuriesit', \"republic's\", \"kingdom's\", '\\u200a4\\u200a', '(originally', 'systemsthe', \"voters'\", \"other's\", 'arties', 'membersa', 'governmentfor', 'functions)', 'historythese', 'electionsin', 'kirchheimer', '\"big', 'principlethe', 'ommon', '\\u200ach', \"workers'\", 'dominant-party', '(of', 'policya', 'governmentit', \"countries'\", 'short-hand', 'theoryother', 'politics)', 'interpretivism', 'pluralismpolitical', 'centuryin', 'phenomenathe', 'sciencein', 'hriker', 'policiesit', 'categoriesthe', \"'two\", '[and]', '(2000)', 'scienceuniversity', '//doi', 'rg/10', 'chase-dunn', 'macmillandoi', 'klingemann', 'alpolitical', 'vol8', 'hallisbn', '(2003)geschichte', '(history', 'ideas)', 'edmunich', '(political', 'research)', 'science\"research', 'dimension)', 'representativesthe', '\"liberal\"', 'wferguson', 'interpretationwhile', 'r-factor', 't-axis', 'tender-minded', 'dimensionthe', 'single-axis', 'authoritarianism\"', 'factor)', 't-factor)', '\"right\"', 'authors)', 'foreigners)', '\"particularly', 'uncertainty\"', 'sciencethe', '(defined', \"(mitchell's\", 'freedom\"', '(issues', '\"ideal', 'axis)', 'vsrural', '\"foreign', 'policy\"', '(states', '(rule', '(total', 'change)', 'πολιτικά', 'philosopherthe', 'affairs\"', 'πόλις', 'processhe', 'governmentwhen', 'vii–viii', '(books', 'regimethe', \"(jaeger's\", 'politicsthe', 'stthomas', 'politicscambridge', \"court's\", 'elected/nominated', 'indiathe', 'partythese', '(6%)', \"kazhagam's\", 'populationfor', '(translated', 'votebank', 'sabka', '(marxist)', 'campaignthe', '(equivalent', \"city's\", 'council)', 'budgetthe', 'statusthe', 'revolutionin', '90%', '\"greater', 'powersthe', 'no9', \"state's\", 'partiesin', \"district's\", 'officein', 'committee)', 'partyhowever', \"citizens'\", 'partiesthey', \"jackson's\", 'lawsome', '(princeton', 'non-significant', 'peoplethis', '15%', 'lsandy', '(16th', '2013)', '2010)', '(11th', '2009)', '1991)', '(2007)', \"'affairs\", \"cities')\", 'scienceit', 'government\"', 'basisthis', 'relationsthe', 'languagesthe', 'behavioralism', 'waysin', 'timocracy', 'statein', 'post-capitalist', '(together', 'macropolitics', 'politicsthis', 'mesopolitics', 'micropolitics', 'outcomesthe', '(1993)', '\"right-wing\"', '[that]', 'europe\"', \"europe's\", 'onservative', '\"survival', 'fittest\"', 'right-', 'order\"', '\"men', 'ultra-royalists', 'rightin', '35%', 'reatwell', 'groupisbn', 'theorythe']\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "embedding_matrix = get_embedding_matrix(word_matrix, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001, 100)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer(embedding_matrix, input_length=SENTENCE_LENGTH, trainable=False):\n",
    "    \"\"\"\n",
    "     Instanzia lo strato di tipo Embedding\n",
    "\n",
    "    :param embedding_matrix: Il dizionario ottenuto dall'embedding avente le parole come indice e il vettore come valore\n",
    "    :param input_length: La lunghezza delle frasi che saranno passate come input\n",
    "    :param trainable: Se True i vettori partecipano all'addestramento e si modificano\n",
    "    \n",
    "    :return: lo strato di tipo Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_layer = Embedding(  # Creiamo un'istanza del layer di tipo Embedding ed impostiamo i parametri indispensabili e quelli necessari per le nostre esigenze\n",
    "                        embedding_matrix.shape[0],  # il numero di righe (numero di parole + 1)\n",
    "                        embedding_matrix.shape[1],  #  il numero di colonne (lunghezza dei vettori)\n",
    "                        weights=[embedding_matrix],  # l'embedding_matrix creata tramite la funzione precedente\n",
    "                        input_length=input_length,  # la lunghezza delle frasi\n",
    "                        trainable=trainable)  # Impostiamo se questo strato deve essere addestrabile o meno, se lo impostiamo addestrabile i vettori si modificheranno\n",
    "\n",
    "    return embedding_layer  # restituiamo lo strato Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model builder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \n",
    "    LAYER_TYPE = hp.Choice(\"LAYER_TYPE\", [\"Dense\", \"Conv1D\", \"LSTM\", \"GRU\"])\n",
    "    TRAINABLE = hp.Boolean(\"TRAINABLE\")\n",
    "    UNITS_L1 = hp.Int('UNITS_L1', min_value=32, max_value=128, step=8)\n",
    "    KERNEL_SIZE = hp.Int('KERNEL_SIZE', min_value=3, max_value=7, step=1)\n",
    "    DROPOUT1 = hp.Float('DROPOUT1', min_value=0.05, max_value=0.5, step=0.05, default=0.3)\n",
    "    DROPOUT2 = hp.Float('DROPOUT2', min_value=0.05, max_value=0.5, step=0.05, default=0.3)\n",
    "    UNITS_L2 = hp.Int('UNITS_L2', min_value=32, max_value=128, step=8, default=128)\n",
    "    DROPOUT3 = hp.Float('DROPOUT3', min_value=0.1, max_value=0.5, step=0.1, default=0.4)\n",
    "    UNITS_L3 = hp.Int('UNITS_L3', min_value=32, max_value=128, step=8, default=64)\n",
    "    DROPOUT4 = hp.Float('DROPOUT4', min_value=0.1, max_value=0.5, step=0.1, default=0.4)\n",
    "    UNITS_L4 = hp.Int('UNITS_L4', min_value=32, max_value=128, step=8, default=64)\n",
    "    DROPOUT5 = hp.Float('DROPOUT5', min_value=0.1, max_value=0.5, step=0.1, default=0.3)\n",
    "    UNITS_L5 = hp.Int('UNITS_L5', min_value=16, max_value=64, step=8, default=48)    \n",
    "    \n",
    "    model = Sequential() \n",
    "    model.add(get_embedding_layer(embedding_matrix, trainable=TRAINABLE)) \n",
    "    if LAYER_TYPE == \"Dense\":\n",
    "        model.add(Dense(UNITS_L1))\n",
    "    elif LAYER_TYPE == \"GRU\":\n",
    "        model.add(Bidirectional(GRU(UNITS_L1, dropout=DROPOUT1)))\n",
    "    elif LAYER_TYPE == \"Conv1D\":    \n",
    "        model.add(Conv1D(filters=UNITS_L1, kernel_size=KERNEL_SIZE, activation=\"relu\"))\n",
    "    model.add(Dropout(DROPOUT2))\n",
    "    model.add(Dense(UNITS_L2))  \n",
    "    model.add(Dropout(DROPOUT3))\n",
    "    model.add(Dense(UNITS_L3)) \n",
    "    model.add(Flatten()) \n",
    "    model.add(Dropout(DROPOUT4))\n",
    "    model.add(Dense(UNITS_L4))\n",
    "    model.add(Dropout(DROPOUT5))\n",
    "    model.add(Dense(UNITS_L5))\n",
    "    model.add(Dense(7, activation='softmax', name=\"Output_Layer\"))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) \n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 60, 100)           1000100   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 60, 32)            3232      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 60, 32)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 60, 128)           4224      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 60, 128)           0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 60, 64)            8256      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3840)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 3840)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                245824    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 48)                3120      \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 7)                 343       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,265,099\n",
      "Trainable params: 264,999\n",
      "Non-trainable params: 1,000,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    model_builder,\n",
    "    max_trials=50,    \n",
    "    overwrite=True, # Con false recupera la ricerca precedente\n",
    "    objective=\"val_acc\",   \n",
    "    directory=\"my_dir\", # directory in cui memorizza i dati temporanei\n",
    "    project_name='keras_tuner-text'\n",
    ")\n",
    "\n",
    "\n",
    "#tuner = kt.Hyperband(model_builder,\n",
    "#                     objective='val_acc',\n",
    "#                     max_epochs=20,\n",
    "#                     factor=3,\n",
    "#                     directory='my_dir',\n",
    "#                     project_name='keras_tuner-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 19s]\n",
      "val_acc: 0.9162929654121399\n",
      "\n",
      "Best val_acc So Far: 0.9282511472702026\n",
      "Total elapsed time: 00h 35m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train, y_train, epochs=25, verbose=1, batch_size=64, validation_data=(X_test, y_test), callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Completata la ricerca degli iperparametri.\n",
      "Il parametro trainable dell'embedding è preferibile sia True  \n",
      "Il layer ottimale dopo l'embeddings è GRU \n",
      "il numero di unità per il layer successivo è 80\n",
      "se è un layer convolutivo la grandezza ottimale del kernel è 6\n",
      "se è un GRU deve avere un dropout di 0.3\n",
      "il primo layer dropout deve essere impostato a 0.05\n",
      "le unità del dense successivo devono essere 120\n",
      "il secondo layer dropout deve essere impostato a 0.1\n",
      "le unità del dense successivo devono essere 104\n",
      "il terzo layer dropout deve essere impostato a 0.30000000000000004\n",
      "le unità del terzultimo dense devono essere 32\n",
      "l'ultimo layer dropout deve essere impostato a 0.30000000000000004\n",
      "le unità del penultimo dense devono essere 16.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "Completata la ricerca degli iperparametri.\n",
    "Il parametro trainable dell'embedding è preferibile sia {best_hps.get('TRAINABLE')}  \n",
    "Il layer ottimale dopo l'embeddings è {best_hps.get('LAYER_TYPE')} \n",
    "il numero di unità per il layer successivo è {best_hps.get('UNITS_L1')}\n",
    "se è un layer convolutivo la grandezza ottimale del kernel è {best_hps.get('KERNEL_SIZE')}\n",
    "se è un GRU deve avere un dropout di {best_hps.get('DROPOUT1')}\n",
    "il primo layer dropout deve essere impostato a {best_hps.get('DROPOUT2')}\n",
    "le unità del dense successivo devono essere {best_hps.get('UNITS_L2')}\n",
    "il secondo layer dropout deve essere impostato a {best_hps.get('DROPOUT3')}\n",
    "le unità del dense successivo devono essere {best_hps.get('UNITS_L3')}\n",
    "il terzo layer dropout deve essere impostato a {best_hps.get('DROPOUT4')}\n",
    "le unità del terzultimo dense devono essere {best_hps.get('UNITS_L4')}\n",
    "l'ultimo layer dropout deve essere impostato a {best_hps.get('DROPOUT5')}\n",
    "le unità del penultimo dense devono essere {best_hps.get('UNITS_L5')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 60, 100)           1000100   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 160)              87360     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 120)               19320     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 104)               12584     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 104)               0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 104)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                3360      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " Output_Layer (Dense)        (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,123,371\n",
      "Trainable params: 1,123,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "42/42 [==============================] - 10s 123ms/step - loss: 1.7369 - acc: 0.3110 - val_loss: 1.3678 - val_acc: 0.5247\n",
      "Epoch 2/30\n",
      "42/42 [==============================] - 4s 99ms/step - loss: 1.2291 - acc: 0.5599 - val_loss: 0.8581 - val_acc: 0.6921\n",
      "Epoch 3/30\n",
      "42/42 [==============================] - 4s 95ms/step - loss: 0.7036 - acc: 0.7556 - val_loss: 0.5031 - val_acc: 0.8296\n",
      "Epoch 4/30\n",
      "42/42 [==============================] - 4s 96ms/step - loss: 0.4048 - acc: 0.8694 - val_loss: 0.3088 - val_acc: 0.8909\n",
      "Epoch 5/30\n",
      "42/42 [==============================] - 4s 97ms/step - loss: 0.3026 - acc: 0.9034 - val_loss: 0.3233 - val_acc: 0.8879\n",
      "Epoch 6/30\n",
      "42/42 [==============================] - 4s 104ms/step - loss: 0.1902 - acc: 0.9446 - val_loss: 0.2957 - val_acc: 0.9148\n",
      "Epoch 7/30\n",
      "42/42 [==============================] - 5s 112ms/step - loss: 0.1741 - acc: 0.9487 - val_loss: 0.2805 - val_acc: 0.9148\n",
      "Epoch 8/30\n",
      "42/42 [==============================] - 5s 110ms/step - loss: 0.1093 - acc: 0.9674 - val_loss: 0.2564 - val_acc: 0.9223\n",
      "Epoch 9/30\n",
      "42/42 [==============================] - 5s 109ms/step - loss: 0.0918 - acc: 0.9704 - val_loss: 0.3580 - val_acc: 0.9058\n",
      "Epoch 10/30\n",
      "42/42 [==============================] - 5s 107ms/step - loss: 0.0843 - acc: 0.9764 - val_loss: 0.2917 - val_acc: 0.9253\n",
      "Epoch 11/30\n",
      "42/42 [==============================] - 5s 111ms/step - loss: 0.0709 - acc: 0.9787 - val_loss: 0.3114 - val_acc: 0.9163\n"
     ]
    }
   ],
   "source": [
    "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(X_train, y_train, epochs=30, verbose=1, batch_size=64, validation_data=(X_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_loss_accuracy(acc, val_acc, loss, val_loss):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plot_loss_accuracy(acc, val_acc, loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"There are two broad stances about what is the world studied by metaphysics. The strong, classical view assumes that the objects studied by metaphysics exist independently of any observer so that the subject is the most fundamental of all sciences.\"\n",
    "text = preprocess_text(text)\n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "print(sequence)\n",
    "padded_seq = pad_sequences(sequence, maxlen=SENTENCE_LENGTH) \n",
    "\n",
    "y = model.predict(padded_seq)\n",
    "print(y)\n",
    "print(np.argmax(y))\n",
    "print(CATEGORIES[np.argmax(y)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
