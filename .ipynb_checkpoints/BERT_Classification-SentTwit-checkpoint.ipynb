{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U \"tensorflow-text==2.8.*\"  # eseguire se non è stato installato in precedenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tf-models-official==2.7.0   # eseguire se non è stato installato in precedenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"./sentDataset/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "NUM_REC = 10000  # Ho dovuto riportare i record a 10.000 perché il triplo input e \n",
    "                 # la grandezza della rete BERT prendevano tutta la memoria rendevano impossibile l'addestramento con 50.000\n",
    "\n",
    "num_pos = 0\n",
    "num_neg = 0\n",
    "with open(DATASET, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        \n",
    "        if num_pos > NUM_REC and num_neg > NUM_REC:\n",
    "            break\n",
    "            \n",
    "        g = int(line[0])\n",
    "        if g > 2:\n",
    "            g = 1\n",
    "            num_pos += 1\n",
    "            if num_pos <= NUM_REC:\n",
    "                y.append(g)\n",
    "                X.append(line[5])\n",
    "        elif g < 2:\n",
    "            g = 0\n",
    "            num_neg += 1\n",
    "            if num_neg <= NUM_REC:\n",
    "                y.append(g) \n",
    "                X.append(line[5])\n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "#raw_train_ds = X_train #tf.keras.utils.text_dataset_from_directory(\n",
    "\n",
    "class_names = [0,1]\n",
    "\n",
    "train_ds = X_train #raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = X_test # tf.keras.utils.text_dataset_from_directory(\n",
    "\n",
    "#val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
      "Pooled Outputs Shape:(1, 512)\n",
      "Pooled Outputs Values:[ 0.76262885  0.99280983 -0.18611872  0.3667386   0.15233792  0.65504557\n",
      "  0.9681154  -0.948627    0.00216077 -0.9877732   0.06842785 -0.9763061 ]\n",
      "Sequence Outputs Shape:(1, 128, 512)\n",
      "Sequence Outputs Values:[[-0.28946352  0.34321296  0.3323149  ...  0.2130083   0.71020764\n",
      "  -0.05771133]\n",
      " [-0.2874205   0.31981108 -0.2301845  ...  0.5845506  -0.2132971\n",
      "   0.7269202 ]\n",
      " [-0.6615705   0.6887687  -0.8743301  ...  0.10877223 -0.26173192\n",
      "   0.47855487]\n",
      " ...\n",
      " [-0.22561216 -0.2892565  -0.07064489 ...  0.4756605   0.832772\n",
      "   0.40025362]\n",
      " [-0.2982421  -0.2747309  -0.05450581 ...  0.48849702  1.095536\n",
      "   0.18163332]\n",
      " [-0.44378197  0.00930689  0.07223699 ...  0.17290227  1.1833242\n",
      "   0.07898021]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In layer  word_embeddings/embeddings:0\n",
      "In layer  position_embedding/embeddings:0\n",
      "In layer  type_embeddings/embeddings:0\n",
      "In layer  embeddings/layer_norm/gamma:0\n",
      "In layer  embeddings/layer_norm/beta:0\n",
      "In layer  transformer/layer_0/self_attention/query/kernel:0\n",
      "In layer  transformer/layer_0/self_attention/query/bias:0\n",
      "In layer  transformer/layer_0/self_attention/key/kernel:0\n",
      "In layer  transformer/layer_0/self_attention/key/bias:0\n",
      "In layer  transformer/layer_0/self_attention/value/kernel:0\n",
      "In layer  transformer/layer_0/self_attention/value/bias:0\n",
      "In layer  transformer/layer_0/self_attention/attention_output/kernel:0\n",
      "In layer  transformer/layer_0/self_attention/attention_output/bias:0\n",
      "In layer  transformer/layer_0/self_attention_layer_norm/gamma:0\n",
      "In layer  transformer/layer_0/self_attention_layer_norm/beta:0\n",
      "In layer  transformer/layer_0/intermediate/kernel:0\n",
      "In layer  transformer/layer_0/intermediate/bias:0\n",
      "In layer  transformer/layer_0/output/kernel:0\n",
      "In layer  transformer/layer_0/output/bias:0\n",
      "In layer  transformer/layer_0/output_layer_norm/gamma:0\n",
      "In layer  transformer/layer_0/output_layer_norm/beta:0\n",
      "In layer  transformer/layer_1/self_attention/query/kernel:0\n",
      "In layer  transformer/layer_1/self_attention/query/bias:0\n",
      "In layer  transformer/layer_1/self_attention/key/kernel:0\n",
      "In layer  transformer/layer_1/self_attention/key/bias:0\n",
      "In layer  transformer/layer_1/self_attention/value/kernel:0\n",
      "In layer  transformer/layer_1/self_attention/value/bias:0\n",
      "In layer  transformer/layer_1/self_attention/attention_output/kernel:0\n",
      "In layer  transformer/layer_1/self_attention/attention_output/bias:0\n",
      "In layer  transformer/layer_1/self_attention_layer_norm/gamma:0\n",
      "In layer  transformer/layer_1/self_attention_layer_norm/beta:0\n",
      "In layer  transformer/layer_1/intermediate/kernel:0\n",
      "In layer  transformer/layer_1/intermediate/bias:0\n",
      "In layer  transformer/layer_1/output/kernel:0\n",
      "In layer  transformer/layer_1/output/bias:0\n",
      "In layer  transformer/layer_1/output_layer_norm/gamma:0\n",
      "In layer  transformer/layer_1/output_layer_norm/beta:0\n",
      "In layer  transformer/layer_2/self_attention/query/kernel:0\n",
      "In layer  transformer/layer_2/self_attention/query/bias:0\n",
      "In layer  transformer/layer_2/self_attention/key/kernel:0\n",
      "In layer  transformer/layer_2/self_attention/key/bias:0\n",
      "In layer  transformer/layer_2/self_attention/value/kernel:0\n",
      "In layer  transformer/layer_2/self_attention/value/bias:0\n",
      "In layer  transformer/layer_2/self_attention/attention_output/kernel:0\n",
      "In layer  transformer/layer_2/self_attention/attention_output/bias:0\n",
      "In layer  transformer/layer_2/self_attention_layer_norm/gamma:0\n",
      "In layer  transformer/layer_2/self_attention_layer_norm/beta:0\n",
      "In layer  transformer/layer_2/intermediate/kernel:0\n",
      "In layer  transformer/layer_2/intermediate/bias:0\n",
      "In layer  transformer/layer_2/output/kernel:0\n",
      "In layer  transformer/layer_2/output/bias:0\n",
      "In layer  transformer/layer_2/output_layer_norm/gamma:0\n",
      "In layer  transformer/layer_2/output_layer_norm/beta:0\n",
      "In layer  transformer/layer_3/self_attention/query/kernel:0\n",
      "In layer  transformer/layer_3/self_attention/query/bias:0\n",
      "In layer  transformer/layer_3/self_attention/key/kernel:0\n",
      "In layer  transformer/layer_3/self_attention/key/bias:0\n",
      "In layer  transformer/layer_3/self_attention/value/kernel:0\n",
      "In layer  transformer/layer_3/self_attention/value/bias:0\n",
      "In layer  transformer/layer_3/self_attention/attention_output/kernel:0\n",
      "In layer  transformer/layer_3/self_attention/attention_output/bias:0\n",
      "In layer  transformer/layer_3/self_attention_layer_norm/gamma:0\n",
      "In layer  transformer/layer_3/self_attention_layer_norm/beta:0\n",
      "In layer  transformer/layer_3/intermediate/kernel:0\n",
      "In layer  transformer/layer_3/intermediate/bias:0\n",
      "In layer  transformer/layer_3/output/kernel:0\n",
      "In layer  transformer/layer_3/output/bias:0\n",
      "In layer  transformer/layer_3/output_layer_norm/gamma:0\n",
      "In layer  transformer/layer_3/output_layer_norm/beta:0\n",
      "In layer  pooler_transform/kernel:0\n",
      "In layer  pooler_transform/bias:0\n",
      "In layer  Variable:0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bert_model.weights)):  # per visualizzare i layer di cui si compone il modello\n",
    "    print(\"In layer \", bert_model.weights[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier model\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "\n",
    "preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "encoder_inputs = preprocessing_layer(text_input)\n",
    "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "outputs = encoder(encoder_inputs)\n",
    "net = outputs['pooled_output']\n",
    "net = tf.keras.layers.Dropout(0.1)(net)\n",
    "net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "\n",
    "classifier_model =  tf.keras.Model(text_input, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " BERT_encoder (KerasLayer)      {'pooled_output': (  28763649    ['preprocessing[0][0]',          \n",
      "                                None, 512),                       'preprocessing[0][1]',          \n",
      "                                 'sequence_output':               'preprocessing[0][2]']          \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 512),                                               \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512),                                                \n",
      "                                 (None, 128, 512)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                512)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['BERT_encoder[0][5]']           \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            513         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,764,162\n",
      "Trainable params: 28,764,161\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifier_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this is such an amazing movie!']\n",
      "tf.Tensor([[0.69800055]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(text_test)\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = len(train_ds) # tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training model with {tfhub_handle_encoder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.python.client import device_lib\n",
    "\n",
    "#def get_available_devices():\n",
    "#    local_device_protos = device_lib.list_local_devices()\n",
    "#    return [x.name for x in local_device_protos if x.device_type == 'GPU' or x.device_type == 'CPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_available_devices())\n",
    "#cpus = tf.config.list_physical_devices('CPU')\n",
    "#print(cpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 4965s 2s/step - loss: 0.6297 - accuracy: 0.6488 - val_loss: 0.5271 - val_accuracy: 0.7490\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 5224s 3s/step - loss: 0.4941 - accuracy: 0.7695 - val_loss: 0.4826 - val_accuracy: 0.7753\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 5122s 3s/step - loss: 0.4343 - accuracy: 0.8116 - val_loss: 0.4874 - val_accuracy: 0.7880\n",
      "Epoch 4/5\n",
      "   3/2000 [..............................] - ETA: 47:40 - loss: 0.2426 - accuracy: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-202f2140dd0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/device:CPU:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mclassifier_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = [tf.keras.metrics.BinaryAccuracy('accuracy', dtype=tf.float32)]\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    classifier_model.compile(\n",
    "                            optimizer=optimizer,\n",
    "                            loss=loss,\n",
    "                            metrics=metrics)\n",
    "\n",
    "with tf.device(\"/device:CPU:0\"):\n",
    "    classifier_model.fit(x=X_train, y=y_train,validation_data=(X_test, y_test),batch_size=8,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ho dovuto interrompere l'addestramento precedente perché mi serviva il computer, che poi ho ripreso sotto con ulteriori 5 epoche\n",
    "\n",
    "PATH_MODEL = \"./models/\"\n",
    "classifier_model.save(PATH_MODEL + 'model_BertSent.h5')  # save the model to file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 4650s 2s/step - loss: 0.3806 - accuracy: 0.8494 - val_loss: 0.6043 - val_accuracy: 0.7688\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 4987s 2s/step - loss: 0.3223 - accuracy: 0.8912 - val_loss: 0.6983 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 4999s 2s/step - loss: 0.2551 - accuracy: 0.9288 - val_loss: 0.9505 - val_accuracy: 0.7872\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 7320s 4s/step - loss: 0.1975 - accuracy: 0.9507 - val_loss: 1.2000 - val_accuracy: 0.7903\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 7006s 4s/step - loss: 0.1559 - accuracy: 0.9642 - val_loss: 1.2405 - val_accuracy: 0.7828\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/device:CPU:0\"):\n",
    "    classifier_model.fit(x=X_train, y=y_train,validation_data=(X_test, y_test),batch_size=8,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo addestramento è stato fatto con 10.000 record perché il triplo input e la grandezza della rete BERT prendevano tutta la memoria rendevano impossibile l'addestramento con 50.000\n",
    "Una prova ulteriore che sarebbe interessante fare e che vi invito a fare è preparare il dataset con 50.000 come nel file TweetSentAnalisys con cui stiamo facendo la comparazione, ma addestrare questa rete prima con 4 o 5 epoche sui primi 10000, e poi successivamente (ovviamente senza ricompilarla, mantenendo l'addestramento precedente) sui 10000 successivi.\n",
    "Se qualcuno lo fa mi faccia sapere come va. Probabilmente lo faccio anch'io."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
