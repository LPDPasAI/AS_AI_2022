{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classifier with transferlearning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import C:\\Users\\lpdepersiis\\AS-AI\\Corso2022\\data_collect_preprocessing.ipynb for ipynb.fs.defs.data_collect_preprocessing: not a valid ipynb file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipynb\\fs\\defs\\__init__.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                     \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    292\u001b[0m     \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m     return loads(fp.read(),\n\u001b[0m\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 23303: character maps to <undefined>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-77aca29ce50d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mipynb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_collect_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_x_y_preprocessed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\ipynb\\fs\\defs\\__init__.py\u001b[0m in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[1;31m# This is if it isn't a valid JSON file at all\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m                     raise ImportError('Could not import {path} for {fn}: not a valid ipynb file'.format(\n\u001b[0m\u001b[0;32m     35\u001b[0m                         \u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import C:\\Users\\lpdepersiis\\AS-AI\\Corso2022\\data_collect_preprocessing.ipynb for ipynb.fs.defs.data_collect_preprocessing: not a valid ipynb file"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import ipynb\n",
    "from ipynb.fs.defs.data_collect_preprocessing import get_x_y_preprocessed\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY_EMBEDDING_PATH = \"C:\\\\Users\\\\lpdepersiis\\\\PycharmProjects\\\\autoencoderNlp\\\\embedding\\\\en\\\\glove\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec, y_rec = get_x_y_preprocessed(\"dataset_cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3449, 7)\n"
     ]
    }
   ],
   "source": [
    "print(y_rec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(x_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index[\"sport\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40977\n"
     ]
    }
   ],
   "source": [
    "print(len(word_index.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_matrix():\n",
    "    \"\"\"\n",
    "    Questa funzione ci serve per crearci un dizionario avente come indice la parola e come valore il vettore dell'embedding corrispondente\n",
    "    \"\"\"\n",
    "    word_matrix = {}\n",
    "    with open(MY_EMBEDDING_PATH + 'glove.6B.100d.txt', 'r', encoding='UTF-8') as file_emb:\n",
    "        for row in file_emb: # leggo ogni riga del file di testo contenente l'embedding\n",
    "            row = row.split() # la divido nei suoi elementi\n",
    "            word_matrix[row[0]] = np.array(row[1:], dtype='float32') # il primo è la parola e sarà l'indice di questa voce, gli altri andranno a formare il vettore \n",
    "    return word_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### proviamo se il dizionario è come ci aspettiamo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_matrix = get_word_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18867  , -0.040943 ,  0.58878  ,  0.11062  ,  0.14236  ,\n",
       "        0.4885   , -0.31832  ,  0.53819  , -0.018549 ,  0.029687 ,\n",
       "        0.30299  , -0.16522  , -0.18896  ,  0.5148   , -0.79405  ,\n",
       "        0.26409  ,  0.027747 ,  0.041163 , -0.49378  , -0.14263  ,\n",
       "        0.29017  , -0.25369  ,  0.70559  , -1.0501   , -0.49344  ,\n",
       "       -0.37148  , -0.85796  , -0.55158  , -0.60251  , -0.0099676,\n",
       "        0.8725   ,  0.12149  ,  0.551    ,  0.49924  , -0.3088   ,\n",
       "        1.1067   , -0.15494  , -0.29923  ,  0.91149  ,  0.19859  ,\n",
       "       -0.73946  , -1.0182   ,  0.37208  , -0.10043  ,  0.13537  ,\n",
       "       -0.52687  , -0.60437  , -0.15906  ,  0.49283  , -0.61386  ,\n",
       "        0.046815 , -0.88806  ,  0.60229  ,  0.72199  , -0.4316   ,\n",
       "       -3.0706   , -0.11233  , -0.45713  ,  0.95737  ,  0.59174  ,\n",
       "       -0.17124  ,  0.65746  ,  0.44741  ,  0.6101   ,  1.0216   ,\n",
       "       -0.2458   ,  0.90191  ,  0.78319  ,  0.28272  , -0.4539   ,\n",
       "        0.16309  , -0.0078932, -0.27714  , -0.87249  , -0.19716  ,\n",
       "       -0.076285 , -0.28422  , -0.089584 , -1.3132   ,  0.16372  ,\n",
       "       -0.25441  , -0.076529 ,  0.44458  , -0.17525  , -0.74084  ,\n",
       "       -0.25415  ,  0.52886  , -0.46958  ,  0.16487  , -0.57443  ,\n",
       "        0.47239  , -0.52798  ,  0.65184  ,  0.803    , -0.93156  ,\n",
       "       -0.055967 ,  0.26932  ,  0.16221  ,  1.1238   , -0.4168   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_matrix[\"house\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ora abbiamo l'indice ottenuto tramite Tokenizer dai nostri testi ed abbiamo un dizionario che fa corrispondere ad ogni parola il vettore corrispondente dell'embedding GloVe, dobbiamo creare una matrice in cui le righe siano nello stesso ordine dell'indice ottenuto dal tokenizer e che contenga solo quei vettori (più lo 0 che è lasciato con un vettore di zeri per essere usato ad indicare l'assenza di una parola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### aggiungo qui la costante relativa alla dimensione dei vettori dell'embedding, perché non si perda la consequenzialità, ma andrebbe messa sopra insieme alle altre variabili (la stessa già impostata nell'altro file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recuperiamo anche la costante relativa alla lunghezza delle frasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_LENGTH = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(embeddings_index, word_index, dim_embeddings=EMBEDDING_DIM):\n",
    "    \"\"\"\n",
    "    Tramite questa funzione creiamo una matrice in cui le righe siano nello stesso ordine dell'indice ottenuto dal tokenizer \n",
    "    e che contenga solo i vettori relativi alle parole in esso contenute\n",
    "    \n",
    "    :param embeddings_index: il dizionario, ottenuto dall'embedding, avente le parole come indice ed i vettori come valore\n",
    "    :param word_index:  il dizionario ottenuto dal tokenizer avente come indice la parola e come valore il suo indice\n",
    "    :param dim_embeddings: la lunghezza dei vettori dell'embedding che stiamo utilizzando\n",
    "    :return: la matrice dei vettori dell'embedding ordinata come il nostro indice\n",
    "\n",
    "    \"\"\"\n",
    "    embedding_matrix = np.zeros((len(word_index) + 1, dim_embeddings))  # creiamo la matrice di zeri avente tante righe quante sono le parole (più una) e tante colonne quante sono quelle dei vettori\n",
    "\n",
    "    for word in word_index.keys():  # Scorriamo le parole dell'indice del tokenizer\n",
    "        embedding_vector = embeddings_index.get(word)  # estraiamo il vettore corrispondente\n",
    "        if embedding_vector is not None:  # verifichiamo che esista (anche se il nostro dizionario è più piccolo di quello dell'embedding potrebbe contenere parolo non presenti in esso)\n",
    "            # se la parola è presente andiamo avanti (se non è presente, in corrispondenza di questo indice, rimarrà il vettore formato da zeri)\n",
    "            embedding_matrix[word_index[word]] = embedding_vector  # impostiamo nella matrice quella riga con il vettore corrispondente alla parola\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ora abbiamo tutti gli elementi per fare lo strato di tipo Embedding che sarà il primo della nostra rete, possiamo scrivere una funzione che lo valorizzi nel modo corretto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedding_matrix(word_matrix, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_layer(embedding_matrix, input_length=SENTENCE_LENGTH, dim_embeddings=EMBEDDING_DIM, trainable=False):\n",
    "    \"\"\"\n",
    "     Instanzia lo strato di tipo Embedding\n",
    "\n",
    "    :param embedding_matrix: Il dizionario ottenuto dall'embedding avente le parole come indice e il vettore come valore\n",
    "    :param input_length: La lunghezza delle frasi che saranno passate come input\n",
    "    :param dim_embeddings: la lunghezza dei vettori\n",
    "    :return: lo strato di tipo Embedding\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_layer = Embedding(  # Creiamo un'istanza del layer di tipo Embedding ed impostiamo i parametri indispensabili e quelli necessari per le nostre esigenze\n",
    "                        embedding_matrix.shape[0],  # il numero di righe (numero di parole + 1)\n",
    "                        dim_embeddings,  #  il numero di colonne (lunghezza dei vettori)\n",
    "                        weights=[embedding_matrix],  # l'embedding_matrix creata tramite la funzione precedente\n",
    "                        input_length=input_length,  # la lunghezza delle frasi\n",
    "                        trainable=trainable)  # Impostiamo se questo strato deve essere addestrabile o meno, se lo impostiamo addestrabile i vettori si modificheranno\n",
    "\n",
    "    return embedding_layer  # restituiamo lo strato Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40978\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ora riprendiamo la pipeline per la realizzazione del classificatore\n",
    "##### trasformiamo la lista di frasi, ciascuna costituita da liste di parole, in liste degli indici corrispondenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(x_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rowing,', 'sometimes', 'referred', 'crew', 'united', 'states,', 'sport', 'whose', 'origins', 'reach', 'back', 'ancient', 'egyptian', 'timesit', 'involves', 'propelling', 'boat', '(racing', 'shell)', 'water', 'using', 'oarsby', 'pushing', 'water', 'oars,', 'rowers', 'generate', 'force', 'move', 'boatthe', 'sport', 'either', 'recreational', 'enjoyment', 'fitness,', 'competitive,', 'athletes', 'race', 'one', 'another', 'boatsthe', 'training', 'physical', 'strain', 'body', 'required', 'successful', 'rower', 'intense']\n"
     ]
    }
   ],
   "source": [
    "print(x_rec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### al posto delle parole della frase precedente sono stati messi gli indici corrispondenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2901, 206, 312, 1575, 51, 287, 23, 476, 1090, 1638, 332, 98, 2665, 9288, 465, 14330, 351, 14331, 14332, 408, 101, 14333, 7116, 408, 7117, 1283, 2666, 726, 1639, 7118, 23, 237, 2667, 3856, 7119, 9289, 127, 368, 7, 183, 14334, 477, 131, 4911, 210, 313, 758, 1284, 2668]\n"
     ]
    }
   ],
   "source": [
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Facciamo il padding per portare tutte le sequenze alla lunghezza impostate con la costante SENTENCE_LENGTH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per farlo dobbiamo importare pad_sequences da keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num_fix = pad_sequences(sequences, maxlen=SENTENCE_LENGTH)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Infatti la sequence precedente è diventata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,  2901,   206,   312,  1575,    51,\n",
       "         287,    23,   476,  1090,  1638,   332,    98,  2665,  9288,\n",
       "         465, 14330,   351, 14331, 14332,   408,   101, 14333,  7116,\n",
       "         408,  7117,  1283,  2666,   726,  1639,  7118,    23,   237,\n",
       "        2667,  3856,  7119,  9289,   127,   368,     7,   183, 14334,\n",
       "         477,   131,  4911,   210,   313,   758,  1284,  2668])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_num_fix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creiamo il modello, prima di farlo dobbiamo importare i layer necessari "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = get_embedding_layer(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 100)           4097800   \n",
      "_________________________________________________________________\n",
      "Layer1 (Dense)               (None, 80, 128)           12928     \n",
      "_________________________________________________________________\n",
      "Layer2 (Dense)               (None, 80, 64)            8256      \n",
      "_________________________________________________________________\n",
      "No_Layer (Flatten)           (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "Layer3 (Dense)               (None, 64)                327744    \n",
      "_________________________________________________________________\n",
      "Layer_n-1 (Dense)            (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 7)                 343       \n",
      "=================================================================\n",
      "Total params: 4,450,191\n",
      "Trainable params: 352,391\n",
      "Non-trainable params: 4,097,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  # Instanziamo Sequential\n",
    "model.add(embedding_layer)  # Aggiungiamo lo strato Embeddings appena creato\n",
    "model.add(Dense(128, name=\"Layer1\"))  # Aggiungiamo i vari layers (gli assegnamo anche un nome per individuarli nella stampa successiva)\n",
    "model.add(Dense(64, name=\"Layer2\"))  \n",
    "model.add(Flatten(name=\"No_Layer\"))  # Aggiungiamo questo per passare dalle due dimensioni avute finora alla dimensione singola\n",
    "model.add(Dense(64, name=\"Layer3\"))\n",
    "model.add(Dense(48, name=\"Layer_n-1\"))\n",
    "model.add(Dense(7, activation='softmax', name=\"Output_Layer\"))  # Lo strato finale ha un numero di neuroni pari al numero di categorie\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])  # Compiliamo il modello definendo loss, metrica per la valutazione (accuratezza) \n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prima di lanciare l'addestramento dividiamo il dataset tra una parte da utilizzare per il train ed una per la validazione  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Per farlo utilizziamo una funzione di sklearn: train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_num_fix, y_rec, test_size=0.20, random_state=42)  # dividiamo il dataset lasciando una parte (0.2 quindi 20%) per la validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lanciamo l'addestramento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 1.6865 - acc: 0.3884 - val_loss: 0.7768 - val_acc: 0.7304\n",
      "Epoch 2/15\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.4362 - acc: 0.8561 - val_loss: 0.7411 - val_acc: 0.7348\n",
      "Epoch 3/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.1937 - acc: 0.9489 - val_loss: 0.7542 - val_acc: 0.7377\n",
      "Epoch 4/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0749 - acc: 0.9924 - val_loss: 0.7913 - val_acc: 0.7536\n",
      "Epoch 5/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.8429 - val_acc: 0.7594\n",
      "Epoch 6/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.8823 - val_acc: 0.7522\n",
      "Epoch 7/15\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.9195 - val_acc: 0.7565\n",
      "Epoch 8/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.9450 - val_acc: 0.7536\n",
      "Epoch 9/15\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.9743 - val_acc: 0.7580\n",
      "Epoch 10/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 1.0070 - val_acc: 0.7536\n",
      "Epoch 11/15\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 1.0193 - val_acc: 0.7609\n",
      "Epoch 12/15\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 1.0356 - val_acc: 0.7580\n",
      "Epoch 13/15\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.0512 - val_acc: 0.7609\n",
      "Epoch 14/15\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 1.0702 - val_acc: 0.7551\n",
      "Epoch 15/15\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.0852 - val_acc: 0.7594\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, verbose=1, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notando che va molto presto in overfitting, è chiaro che dovremmo aumentare il numero degli esempi andando a raccogliere altri documenti, comunque possiamo provare ad aggiungere un po' di dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 100)           4097800   \n",
      "_________________________________________________________________\n",
      "Layer1 (Dense)               (None, 80, 128)           12928     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80, 128)           0         \n",
      "_________________________________________________________________\n",
      "Layer2 (Dense)               (None, 80, 64)            8256      \n",
      "_________________________________________________________________\n",
      "No_Layer (Flatten)           (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "Layer3 (Dense)               (None, 64)                327744    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Layer_n-1 (Dense)            (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 7)                 343       \n",
      "=================================================================\n",
      "Total params: 4,450,191\n",
      "Trainable params: 352,391\n",
      "Non-trainable params: 4,097,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(embedding_layer) \n",
    "model.add(Dense(128, name=\"Layer1\"))  \n",
    "model.add(Dropout(0.3)) # Strato di Dropout che ad ogni passaggio disabilita una certa quantità di connessioni (in questo caso il 30%)\n",
    "model.add(Dense(64, name=\"Layer2\"))  \n",
    "model.add(Flatten(name=\"No_Layer\"))\n",
    "model.add(Dense(64, name=\"Layer3\"))\n",
    "model.add(Dropout(0.2)) # Qui ne disabilitiamo il 20%\n",
    "model.add(Dense(48, name=\"Layer_n-1\"))\n",
    "model.add(Dense(7, activation='softmax', name=\"Output_Layer\"))  \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])  \n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 1.8021 - acc: 0.3710 - val_loss: 0.7842 - val_acc: 0.7275\n",
      "Epoch 2/15\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.5529 - acc: 0.8115 - val_loss: 0.6589 - val_acc: 0.7594\n",
      "Epoch 3/15\n",
      "22/22 [==============================] - 1s 31ms/step - loss: 0.3603 - acc: 0.8844 - val_loss: 0.6465 - val_acc: 0.7739\n",
      "Epoch 4/15\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.2258 - acc: 0.9341 - val_loss: 0.7032 - val_acc: 0.7870\n",
      "Epoch 5/15\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.1424 - acc: 0.9613 - val_loss: 0.7864 - val_acc: 0.7638\n",
      "Epoch 6/15\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.1096 - acc: 0.9644 - val_loss: 0.8049 - val_acc: 0.7681\n",
      "Epoch 7/15\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0866 - acc: 0.9760 - val_loss: 0.9059 - val_acc: 0.7507\n",
      "Epoch 8/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0797 - acc: 0.9739 - val_loss: 0.9651 - val_acc: 0.7580\n",
      "Epoch 9/15\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0596 - acc: 0.9811 - val_loss: 0.9812 - val_acc: 0.7565\n",
      "Epoch 10/15\n",
      "22/22 [==============================] - 1s 34ms/step - loss: 0.0504 - acc: 0.9812 - val_loss: 1.0774 - val_acc: 0.7667\n",
      "Epoch 11/15\n",
      "22/22 [==============================] - 1s 32ms/step - loss: 0.0567 - acc: 0.9800 - val_loss: 1.0769 - val_acc: 0.7609\n",
      "Epoch 12/15\n",
      "22/22 [==============================] - 1s 33ms/step - loss: 0.0375 - acc: 0.9879 - val_loss: 1.0657 - val_acc: 0.7725\n",
      "Epoch 13/15\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0385 - acc: 0.9902 - val_loss: 1.2354 - val_acc: 0.7652\n",
      "Epoch 14/15\n",
      "22/22 [==============================] - 1s 41ms/step - loss: 0.0357 - acc: 0.9871 - val_loss: 1.1434 - val_acc: 0.7710\n",
      "Epoch 15/15\n",
      "22/22 [==============================] - 1s 42ms/step - loss: 0.0333 - acc: 0.9886 - val_loss: 1.2267 - val_acc: 0.7667\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, verbose=1, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A questo punto si posso provare altri aggiustamenti, tra cui soprattutto aggiungere strati più sofisticati che prevedono convoluzione e ricorrenza\n",
    "### Ad esempio Conv1D, Bidirectional, GRU, LSTM ecc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Bidirectional, GRU, LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 100)           4097800   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               63744     \n",
      "_________________________________________________________________\n",
      "Layer1 (Dense)               (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "Layer2 (Dense)               (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "No_Layer (Flatten)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Layer3 (Dense)               (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "Layer_n-1 (Dense)            (None, 48)                3120      \n",
      "_________________________________________________________________\n",
      "Output_Layer (Dense)         (None, 7)                 343       \n",
      "=================================================================\n",
      "Total params: 4,193,935\n",
      "Trainable params: 96,135\n",
      "Non-trainable params: 4,097,800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(embedding_layer)  \n",
    "model.add(Bidirectional(GRU(64)))\n",
    "model.add(Dense(128, name=\"Layer1\"))  \n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, name=\"Layer2\")) \n",
    "model.add(Flatten(name=\"No_Layer\")) \n",
    "model.add(Dense(64, name=\"Layer3\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(48, name=\"Layer_n-1\"))\n",
    "model.add(Dense(7, activation='softmax', name=\"Output_Layer\"))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) \n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22/22 [==============================] - 6s 107ms/step - loss: 1.8810 - acc: 0.2389 - val_loss: 1.5454 - val_acc: 0.4319\n",
      "Epoch 2/15\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 1.5160 - acc: 0.4577 - val_loss: 1.3077 - val_acc: 0.5333\n",
      "Epoch 3/15\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 1.3137 - acc: 0.5332 - val_loss: 1.1386 - val_acc: 0.5942\n",
      "Epoch 4/15\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 1.0714 - acc: 0.6017 - val_loss: 0.8581 - val_acc: 0.6957\n",
      "Epoch 5/15\n",
      "22/22 [==============================] - 3s 119ms/step - loss: 0.7473 - acc: 0.7265 - val_loss: 0.6839 - val_acc: 0.7623\n",
      "Epoch 6/15\n",
      "22/22 [==============================] - 2s 114ms/step - loss: 0.6010 - acc: 0.7973 - val_loss: 0.5808 - val_acc: 0.8087\n",
      "Epoch 7/15\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.4900 - acc: 0.8262 - val_loss: 0.5091 - val_acc: 0.8319\n",
      "Epoch 8/15\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.4386 - acc: 0.8519 - val_loss: 0.5031 - val_acc: 0.8333\n",
      "Epoch 9/15\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.3904 - acc: 0.8595 - val_loss: 0.4685 - val_acc: 0.8348\n",
      "Epoch 10/15\n",
      "22/22 [==============================] - 2s 108ms/step - loss: 0.3425 - acc: 0.8831 - val_loss: 0.4850 - val_acc: 0.8362\n",
      "Epoch 11/15\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 0.2827 - acc: 0.9029 - val_loss: 0.4399 - val_acc: 0.8522\n",
      "Epoch 12/15\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.2495 - acc: 0.9163 - val_loss: 0.4612 - val_acc: 0.8449\n",
      "Epoch 13/15\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.2453 - acc: 0.9126 - val_loss: 0.4841 - val_acc: 0.8493\n",
      "Epoch 14/15\n",
      "22/22 [==============================] - 2s 105ms/step - loss: 0.2320 - acc: 0.9167 - val_loss: 0.4447 - val_acc: 0.8594\n",
      "Epoch 15/15\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.2150 - acc: 0.9247 - val_loss: 0.5320 - val_acc: 0.8493\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=15, verbose=1, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'accuratezza del dataset di validazione è decisamente maggiore ed abbiamo ancora margine avendo una loss ancora alta e l'accuratezza del train set ancora sotto l'1\n",
    "### Lanciamo nuovamente l'addestramento facendo altre 9 epoche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "22/22 [==============================] - 2s 78ms/step - loss: 0.2041 - acc: 0.9268 - val_loss: 0.4723 - val_acc: 0.8623\n",
      "Epoch 2/9\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.1645 - acc: 0.9424 - val_loss: 0.4917 - val_acc: 0.8623\n",
      "Epoch 3/9\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.1602 - acc: 0.9424 - val_loss: 0.5496 - val_acc: 0.8638\n",
      "Epoch 4/9\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.1358 - acc: 0.9532 - val_loss: 0.5544 - val_acc: 0.8594\n",
      "Epoch 5/9\n",
      "22/22 [==============================] - 2s 72ms/step - loss: 0.1304 - acc: 0.9540 - val_loss: 0.5970 - val_acc: 0.8551\n",
      "Epoch 6/9\n",
      "22/22 [==============================] - 2s 109ms/step - loss: 0.1380 - acc: 0.9518 - val_loss: 0.5598 - val_acc: 0.8536\n",
      "Epoch 7/9\n",
      "22/22 [==============================] - 2s 110ms/step - loss: 0.1214 - acc: 0.9576 - val_loss: 0.5706 - val_acc: 0.8580\n",
      "Epoch 8/9\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 0.0888 - acc: 0.9677 - val_loss: 0.5866 - val_acc: 0.8696\n",
      "Epoch 9/9\n",
      "22/22 [==============================] - 2s 106ms/step - loss: 0.0673 - acc: 0.9779 - val_loss: 0.6253 - val_acc: 0.8725\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=9, verbose=1, batch_size=128, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proviamo il modello con delle frasi nuove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.data_collect_preprocessing import preprocess_text\n",
    "from ipynb.fs.defs.data_collect_preprocessing import CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24, 909, 16901, 15, 580, 18113, 138, 219, 2421, 425, 580, 1413, 787, 2073, 8182, 385, 502]]\n",
      "[[1.4379261e-04 7.1372865e-06 4.3864366e-06 2.1024236e-05 9.9956983e-01\n",
      "  6.4953265e-06 2.4726757e-04]]\n",
      "4\n",
      "philosophy\n"
     ]
    }
   ],
   "source": [
    "text = \"There are two broad stances about what is the world studied by metaphysics. The strong, classical view assumes that the objects studied by metaphysics exist independently of any observer so that the subject is the most fundamental of all sciences.\"\n",
    "text = preprocess_text(text)\n",
    "sequence = tokenizer.texts_to_sequences([text])\n",
    "print(sequence)\n",
    "padded_seq = pad_sequences(sequence, maxlen=SENTENCE_LENGTH) \n",
    "y = model.predict(padded_seq)\n",
    "print(y)\n",
    "print(np.argmax(y))\n",
    "print(CATEGORIES[np.argmax(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
