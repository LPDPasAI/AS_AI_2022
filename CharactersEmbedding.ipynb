{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characters Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import array\n",
    "from pickle import load, dump\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metaparameters\n",
    "PATH_DATASET = \"./dataset/\"\n",
    "PATH_MODEL = \"./models/\"\n",
    "PATH_CATEGORIES = PATH_DATASET + \"categories/\"\n",
    "SEQUENCE_LENGTH = 20  # The length of the sentences into which we will divide the text.\n",
    "LSTM_CELLS = 500  # The number of neurons in the LSTM. If you have to learn a very long text, it is better to increase this number, if the text to be learned is small, much less may be enough (even less than 100).\n",
    "filename = 'all_categories'  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removal_old(text):\n",
    "    text = re.sub('@', '', text)    \n",
    "    text = re.sub('#', '', text)    \n",
    "    text = re.sub('°', '', text)\n",
    "    text = re.sub('§', '', text)\n",
    "    text = re.sub('ɑ', '', text)\n",
    "    text = re.sub('ɔ', '', text)\n",
    "    text = re.sub('ə', '', text)\n",
    "    text = re.sub('ʃ', '', text)\n",
    "    text = re.sub('ά', '', text)\n",
    "    text = re.sub('έ', '', text)\n",
    "    text = re.sub('ή', '', text)\n",
    "    text = re.sub('α', '', text)\n",
    "    text = re.sub('β', '', text)\n",
    "    text = re.sub('γ', '', text)\n",
    "    text = re.sub('δ', '', text)\n",
    "    text = re.sub('ε', '', text)\n",
    "    text = re.sub('η', '', text)\n",
    "    text = re.sub('θ', '', text)\n",
    "    text = re.sub('ι', '', text)\n",
    "    text = re.sub('κ', '', text)\n",
    "    text = re.sub('λ', '', text)\n",
    "    text = re.sub('μ', '', text)\n",
    "    text = re.sub('ν', '', text)\n",
    "    text = re.sub('ξ', '', text)\n",
    "    text = re.sub('ο', '', text)\n",
    "    text = re.sub('π', '', text)\n",
    "    text = re.sub('ρ', '', text)\n",
    "    text = re.sub('ς', '', text)\n",
    "    text = re.sub('σ', '', text)\n",
    "    text = re.sub('τ', '', text)\n",
    "    text = re.sub('υ', '', text)\n",
    "    text = re.sub('φ', '', text)\n",
    "    text = re.sub('χ', '', text)\n",
    "    text = re.sub('ψ', '', text)\n",
    "    text = re.sub('ω', '', text)\n",
    "    #text = re.sub('<[/\\'\\\"A-Za-z0-9=A-Za-z0-9\\'\\\"]*>', '', text) # rimozione tag\n",
    "    text = re.sub('<[^>]*>', '', text) # rimozione tag   \n",
    "    #text = re.sub('\\...', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_removal(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # rimozione tag\n",
    "    text = re.sub('[^a-zA-Z0-9 .:,;èòóàùúéìí]*', '', text)     \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 !\n",
      "34 \"\n",
      "35 #\n",
      "36 $\n",
      "37 %\n",
      "38 &\n",
      "39 '\n",
      "40 (\n",
      "41 )\n",
      "42 *\n",
      "43 +\n",
      "44 ,\n",
      "45 -\n",
      "46 .\n",
      "47 /\n",
      "48 0\n",
      "49 1\n",
      "50 2\n",
      "51 3\n",
      "52 4\n",
      "53 5\n",
      "54 6\n",
      "55 7\n",
      "56 8\n",
      "57 9\n",
      "58 :\n",
      "59 ;\n",
      "60 <\n",
      "61 =\n",
      "62 >\n",
      "63 ?\n",
      "64 @\n",
      "65 A\n",
      "66 B\n",
      "67 C\n",
      "68 D\n",
      "69 E\n",
      "70 F\n",
      "71 G\n",
      "72 H\n",
      "73 I\n",
      "74 J\n",
      "75 K\n",
      "76 L\n",
      "77 M\n",
      "78 N\n",
      "79 O\n",
      "80 P\n",
      "81 Q\n",
      "82 R\n",
      "83 S\n",
      "84 T\n",
      "85 U\n",
      "86 V\n",
      "87 W\n",
      "88 X\n",
      "89 Y\n",
      "90 Z\n",
      "91 [\n",
      "92 \\\n",
      "93 ]\n",
      "94 ^\n",
      "95 _\n",
      "96 `\n",
      "97 a\n",
      "98 b\n",
      "99 c\n",
      "100 d\n",
      "101 e\n",
      "102 f\n",
      "103 g\n",
      "104 h\n",
      "105 i\n",
      "106 j\n",
      "107 k\n",
      "108 l\n",
      "109 m\n",
      "110 n\n",
      "111 o\n",
      "112 p\n",
      "113 q\n",
      "114 r\n",
      "115 s\n",
      "116 t\n",
      "117 u\n",
      "118 v\n",
      "119 w\n",
      "120 x\n",
      "121 y\n",
      "122 z\n",
      "123 {\n",
      "124 |\n",
      "125 }\n",
      "126 ~\n",
      "127 \n",
      "128 \n",
      "129 \n",
      "130 \n",
      "131 \n",
      "132 \n",
      "133 ",
      "\n",
      "134 \n",
      "135 \n",
      "136 \n",
      "137 \n",
      "138 \n",
      "139 \n",
      "140 \n",
      "141 \n",
      "142 \n",
      "143 \n",
      "144 \n",
      "145 \n",
      "146 \n",
      "147 \n",
      "148 \n",
      "149 \n",
      "150 \n",
      "151 \n",
      "152 \n",
      "153 \n",
      "154 \n",
      "155 \n",
      "156 \n",
      "157 \n",
      "158 \n",
      "159 \n",
      "160  \n",
      "161 ¡\n",
      "162 ¢\n",
      "163 £\n",
      "164 ¤\n",
      "165 ¥\n",
      "166 ¦\n",
      "167 §\n",
      "168 ¨\n",
      "169 ©\n",
      "170 ª\n",
      "171 «\n",
      "172 ¬\n",
      "173 ­\n",
      "174 ®\n",
      "175 ¯\n",
      "176 °\n",
      "177 ±\n",
      "178 ²\n",
      "179 ³\n",
      "180 ´\n",
      "181 µ\n",
      "182 ¶\n",
      "183 ·\n",
      "184 ¸\n",
      "185 ¹\n",
      "186 º\n",
      "187 »\n",
      "188 ¼\n",
      "189 ½\n",
      "190 ¾\n",
      "191 ¿\n",
      "192 À\n",
      "193 Á\n",
      "194 Â\n",
      "195 Ã\n",
      "196 Ä\n",
      "197 Å\n",
      "198 Æ\n",
      "199 Ç\n",
      "200 È\n",
      "201 É\n",
      "202 Ê\n",
      "203 Ë\n",
      "204 Ì\n",
      "205 Í\n",
      "206 Î\n",
      "207 Ï\n",
      "208 Ð\n",
      "209 Ñ\n",
      "210 Ò\n",
      "211 Ó\n",
      "212 Ô\n",
      "213 Õ\n",
      "214 Ö\n",
      "215 ×\n",
      "216 Ø\n",
      "217 Ù\n",
      "218 Ú\n",
      "219 Û\n",
      "220 Ü\n",
      "221 Ý\n",
      "222 Þ\n",
      "223 ß\n",
      "224 à\n",
      "225 á\n",
      "226 â\n",
      "227 ã\n",
      "228 ä\n",
      "229 å\n",
      "230 æ\n",
      "231 ç\n",
      "232 è\n",
      "233 é\n",
      "234 ê\n",
      "235 ë\n",
      "236 ì\n",
      "237 í\n",
      "238 î\n",
      "239 ï\n",
      "240 ð\n",
      "241 ñ\n",
      "242 ò\n",
      "243 ó\n",
      "244 ô\n",
      "245 õ\n",
      "246 ö\n",
      "247 ÷\n",
      "248 ø\n",
      "249 ù\n",
      "250 ú\n",
      "251 û\n",
      "252 ü\n",
      "253 ý\n",
      "254 þ\n",
      "255 ÿ\n"
     ]
    }
   ],
   "source": [
    "for c in range(33, 256):\n",
    "    print(c, chr(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " titolo   paragrafo   Imo this is ok. b4n\n"
     ]
    }
   ],
   "source": [
    "testo = \" <div><h1>titolo </h1> <div id='app'>§§ °paragrafo° §§ <p> Imo this is ok. b4n</div></div>\"\n",
    "print(noise_removal(testo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_removal(text):\n",
    "    text = text.replace(\"    \", \" \")\n",
    "    text = text.replace(\"   \", \" \")\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    text = text.replace(\"  \", \" \")    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(text):\n",
    "    text = text.replace(\":-)\", \"smile\")\n",
    "    text = text.replace(\":)\", \"smile\")\n",
    "    text = text.replace(\":D\", \"smile\")\n",
    "    text = text.replace(\"b4n\", \"bye for now\")    \n",
    "    text = text.replace(\"b4\", \"before\")\n",
    "    text = text.replace(\"lmk\", \"let me know\")\n",
    "    text = text.replace(\"nmd\", \"nevermind\")\n",
    "    text = text.replace(\"imo\", \"in my opinion\")\n",
    "    text = text.replace(\"tia\", \"thanks in advance\")\n",
    "    text = text.replace(\"?4u\", \"i have a question for you\")\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\":\", \" : \")\n",
    "    text = text.replace(\";\", \" ; \")\n",
    "    text = space_removal(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = normalization(text)\n",
    "    text = noise_removal(text)\n",
    "    text = space_removal(text)\n",
    "   # text = text.split(' ')  # non vanno divise\n",
    "   # text = stopword_removal(text) # meglio non rimuoverle\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " titolo paragrafo in my opinion this is ok . bye for now\n"
     ]
    }
   ],
   "source": [
    "print(preprocess_text(testo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dataset_cat.csv', 'economics', 'literature', 'philosophy', 'physics', 'politics', 'psychology', 'sport']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(PATH_DATASET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: ['economics', 'literature', 'philosophy', 'physics', 'politics', 'psychology', 'sport']\n"
     ]
    }
   ],
   "source": [
    "categories = []\n",
    "with os.scandir(PATH_DATASET) as it:\n",
    "    for entry in it:\n",
    "        if not entry.name.startswith('.') and entry.is_dir():\n",
    "            categories.append(entry.name)\n",
    "print(\"categories:\", categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['literature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(name_file, categories):\n",
    "    count = 0\n",
    "    with open(PATH_DATASET + name_file + \".txt\", 'w', newline='', encoding='UTF-8') as file_out:\n",
    "        for idx, cat in enumerate(categories):\n",
    "            print(\"\\n *** Importing\", cat)\n",
    "            path_cat = PATH_DATASET + cat + \"/\"\n",
    "            files = os.listdir(path_cat)\n",
    "            print(files)\n",
    "            for f in files:\n",
    "                with open(path_cat + f, 'r', encoding='UTF-8') as file_in:\n",
    "                    file_text = file_in.read()\n",
    "                    file_out.write(file_text)\n",
    "            print(count)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " *** Importing literature\n",
      "['History of literature.txt', 'Literature review.txt', 'Literature.txt', 'Nobel Prize in Literature.txt', 'Victorian literature.txt', 'Western literature.txt', 'World literature.txt']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import_dataset(\"all_categories\", ['literature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_preprocess_file_text(file_name):\n",
    "    \"\"\"\n",
    "    Load the file's text and preprocess it\n",
    "    :param file_name: the file to open\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    with open(PATH_DATASET + file_name, 'r', encoding='UTF-8') as file: # open the file as read only\n",
    "        text = file.read()  # read the file and get text\n",
    "        text = preprocess_text(text)  # preprocess text (this step can also be skipped)\n",
    "\n",
    "    return text  # return the text of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sequences(text):\n",
    "    \"\"\"\n",
    "    Split text into sequences of characters SEQUENCE_LENGTH characters long\n",
    "    the sequences are created by shifting, for each subsequent sequence, by one character with respect to the previous one\n",
    "    :param text: the text to split\n",
    "    :return: the list of sequences\n",
    "    \"\"\"\n",
    "    length = SEQUENCE_LENGTH  # the length of the sequences set by the metaparameter\n",
    "    sequences = []  # The list that will contain the sequences\n",
    "    for i in range(len(text) - length):  # repeats the following operations with i taking values from 0 to the length of the text passed - SEQUENCE_LENGTH\n",
    "        seq = text[i: length + i + 1]  # The first sequence will consist of the first characters length of the text +1, then the same length starting from the second and so on ...\n",
    "        sequences.append(seq)  # Add the sequence to the list\n",
    "    print('Number of sequences: ' + str(len(sequences)))  # print the number of sequences\n",
    "    return sequences  # the list of sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saved_model(id=''):\n",
    "    try: \n",
    "        model = load_model(PATH_MODEL + 'model'+id+'.h5')  \n",
    "        mapping = load(open(PATH_MODEL + 'mapping'+id+'.pkl', 'rb')) \n",
    "        print(\"Continuing train on saved model... \")  \n",
    "    except Exception as e: \n",
    "        print(\"Files non found \", e) \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_char):\n",
    "    \"\"\"\n",
    "    Prepare the model based on the number of characters of the mapping\n",
    "    (which determines the output layer and the second dimension of the input)\n",
    "    and the length of the sequences.\n",
    "    :param num_char: the number of characters of the mapping\n",
    "    :return: the model ready for training\n",
    "    \"\"\"\n",
    "    model = Sequential()  # Let's create an instance of the Keras object that allows you to create a network in a very simple way\n",
    "    model.add(LSTM(LSTM_CELLS, input_shape=(SEQUENCE_LENGTH, num_char)))  # The number of neurons is the LSTM_CELLS metaparameter defined at the beginning of the script, the size of the input is given by the number of characters in the mapping and the length of the sequences\n",
    "    model.add(Dense(num_char, activation='softmax'))  # The size of the output is determined by the number of characters in the mapping\n",
    "    print(model.summary())  # print the model schema\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # we compile the model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 138631\n"
     ]
    }
   ],
   "source": [
    "# The file containing the text on which the training will be carried out can be as short or long as you like.\n",
    "# Adjust the metaparameters also according to this.\n",
    "# If very short LSTM_CELLS can be even 100 or less, if it is about 50,000 characters it is recommended to set it to at least 300, if about 100,000 LSTM_CELLS it should be at least 500 and so on...\n",
    "\n",
    "\n",
    "text = get_and_preprocess_file_text(filename + \".txt\")  # Load the file and do a minimal preprocessing.\n",
    "sequences = split_in_sequences(text)  # Split text into sequences of characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, ',': 1, '.': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, ':': 13, ';': 14, 'a': 15, 'b': 16, 'c': 17, 'd': 18, 'e': 19, 'f': 20, 'g': 21, 'h': 22, 'i': 23, 'j': 24, 'k': 25, 'l': 26, 'm': 27, 'n': 28, 'o': 29, 'p': 30, 'q': 31, 'r': 32, 's': 33, 't': 34, 'u': 35, 'v': 36, 'w': 37, 'x': 38, 'y': 39, 'z': 40, 'è': 41, 'é': 42, 'í': 43, 'ó': 44}\n"
     ]
    }
   ],
   "source": [
    "# To get an ordered list of the set of characters present in the text\n",
    "chars = sorted(list(set(text)))  # First we get a set from the text (so each different character is taken only once), then this set of characters is transformed into a list and sorted\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))  # Let's create a dictionary that maps characters\n",
    "print(mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 500)               1092000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 45)                22545     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,114,545\n",
      "Trainable params: 1,114,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = get_model(len(mapping))  # Prepare the model based on the number of characters of the mapping and the length of the sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = []  # a new list that will contain the character sequences encoded according to the mapping\n",
    "for line in sequences:  # We go through all the sequences contained in the list and prepared previously\n",
    "    encoded_seq = [mapping[char] for char in line]  # Each character in the sequence is replaced by the corresponding integer based on the mapping\n",
    "    encoded_sequences.append(encoded_seq)  # The new sequence (now no longer of characters but of numbers) is added to the list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = array(encoded_sequences)  # We transform the list of lists into a numpy matrix.\n",
    "X, y = encoded_sequences[:, :-1], encoded_sequences[:, -1]  # We derive a matrix and a vector. The matrix X is made from the same rows of encoded_sequences without the last element, the vector only from the last element of those rows.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (138631, 20, 45)\n",
      "y.shape: (138631, 45)\n",
      "SEQUENCE_LENGTH: 20 len(mapping): 45\n"
     ]
    }
   ],
   "source": [
    "encoded_sequences = [to_categorical(x, num_classes=len(mapping)) for x in X]  # Convert encoding numbers of sequences to one-hot vectors\n",
    "X = array(encoded_sequences)\n",
    "y = to_categorical(y, num_classes=len(mapping))  # Convert encoding numbers of target characters to one-hot vectors\n",
    "print(\"X.shape: \" + str(X.shape))\n",
    "print(\"y.shape: \" + str(y.shape))\n",
    "print(\"SEQUENCE_LENGTH: \" + str(SEQUENCE_LENGTH), \"len(mapping): \" + str(len(mapping)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2167/2167 [==============================] - 427s 196ms/step - loss: 2.2147 - accuracy: 0.3584\n",
      "Epoch 2/15\n",
      "2167/2167 [==============================] - 425s 196ms/step - loss: 1.7126 - accuracy: 0.4971\n",
      "Epoch 3/15\n",
      "2167/2167 [==============================] - 427s 197ms/step - loss: 1.4893 - accuracy: 0.5621\n",
      "Epoch 4/15\n",
      "2167/2167 [==============================] - 427s 197ms/step - loss: 1.3403 - accuracy: 0.6036\n",
      "Epoch 5/15\n",
      "2167/2167 [==============================] - 429s 198ms/step - loss: 1.2120 - accuracy: 0.6374\n",
      "Epoch 6/15\n",
      "2167/2167 [==============================] - 435s 201ms/step - loss: 1.0902 - accuracy: 0.6724\n",
      "Epoch 7/15\n",
      "2167/2167 [==============================] - 439s 203ms/step - loss: 0.9759 - accuracy: 0.7029\n",
      "Epoch 8/15\n",
      "2167/2167 [==============================] - 436s 201ms/step - loss: 0.8658 - accuracy: 0.7359\n",
      "Epoch 9/15\n",
      "2167/2167 [==============================] - 440s 203ms/step - loss: 0.7639 - accuracy: 0.7665\n",
      "Epoch 10/15\n",
      "2167/2167 [==============================] - 438s 202ms/step - loss: 0.6753 - accuracy: 0.7928\n",
      "Epoch 11/15\n",
      "2167/2167 [==============================] - 457s 211ms/step - loss: 0.5973 - accuracy: 0.8165\n",
      "Epoch 12/15\n",
      "2167/2167 [==============================] - 438s 202ms/step - loss: 0.5325 - accuracy: 0.8369\n",
      "Epoch 13/15\n",
      "2167/2167 [==============================] - 438s 202ms/step - loss: 0.4771 - accuracy: 0.8533\n",
      "Epoch 14/15\n",
      "2167/2167 [==============================] - 442s 204ms/step - loss: 0.4369 - accuracy: 0.8646\n",
      "Epoch 15/15\n",
      "2167/2167 [==============================] - 440s 203ms/step - loss: 0.3956 - accuracy: 0.8782\n"
     ]
    }
   ],
   "source": [
    "epochs_def = 15\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=3, min_delta=0.00001)  # By setting the EarlyStopping we ask that the train be stopped when the set conditions occur (in our case there is no appreciable improvement for 4 epochs)\n",
    "callback = [es]  # To set the early stopping we have to put it in a list (which could also contain other objects for other settings, here https://keras.io/api/callbacks/ more details are available)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model.fit(X, y, epochs=epochs_def, verbose=1, batch_size=64, callbacks=callback)  # With this call we start training the network. We pass them our examples (X) and the desired answers (y), the number of epochs and the callbacks we want to set (in our case only early stopping).\n",
    "\n",
    "model.save(PATH_MODEL + 'model.h5')  # save the model to file\n",
    "dump(mapping, open(PATH_MODEL + 'mapping.pkl', 'wb'))  # And save the mapping with which the text used for training was encoded (and it will be used for text to be used for predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1084/1084 [==============================] - 308s 284ms/step - loss: 0.2414 - accuracy: 0.9354\n",
      "Epoch 2/15\n",
      "1084/1084 [==============================] - 305s 282ms/step - loss: 0.1591 - accuracy: 0.9631\n",
      "Epoch 3/15\n",
      "1084/1084 [==============================] - 306s 282ms/step - loss: 0.1761 - accuracy: 0.9553\n",
      "Epoch 4/15\n",
      "1084/1084 [==============================] - 306s 282ms/step - loss: 0.1994 - accuracy: 0.9443\n",
      "Epoch 5/15\n",
      "1084/1084 [==============================] - 305s 281ms/step - loss: 0.1647 - accuracy: 0.9563\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs_def = 15\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=3, min_delta=0.001)  # By setting the EarlyStopping we ask that the train be stopped when the set conditions occur (in our case there is no appreciable improvement for 4 epochs)\n",
    "callback = [es]  # To set the early stopping we have to put it in a list (which could also contain other objects for other settings, here https://keras.io/api/callbacks/ more details are available)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model.fit(X, y, epochs=epochs_def, verbose=1, batch_size=128, callbacks=callback)  # With this call we start training the network. We pass them our examples (X) and the desired answers (y), the number of epochs and the callbacks we want to set (in our case only early stopping).\n",
    "\n",
    "model.save(PATH_MODEL + 'model.h5')  # save the model to file\n",
    "dump(mapping, open(PATH_MODEL + 'mapping.pkl', 'wb'))  # And save the mapping with which the text used for training was encoded (and it will be used for text to be used for predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "542/542 [==============================] - 265s 489ms/step - loss: 0.0970 - accuracy: 0.9790\n",
      "Epoch 2/4\n",
      "542/542 [==============================] - 265s 489ms/step - loss: 0.0490 - accuracy: 0.9907\n",
      "Epoch 3/4\n",
      "542/542 [==============================] - 264s 487ms/step - loss: 0.0417 - accuracy: 0.9913\n",
      "Epoch 4/4\n",
      "542/542 [==============================] - 264s 488ms/step - loss: 0.0412 - accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "epochs_def = 4\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=3, min_delta=0.01)  # By setting the EarlyStopping we ask that the train be stopped when the set conditions occur (in our case there is no appreciable improvement for 4 epochs)\n",
    "callback = [es]  # To set the early stopping we have to put it in a list (which could also contain other objects for other settings, here https://keras.io/api/callbacks/ more details are available)\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model.fit(X, y, epochs=epochs_def, verbose=1, batch_size=256, callbacks=callback)  # With this call we start training the network. We pass them our examples (X) and the desired answers (y), the number of epochs and the callbacks we want to set (in our case only early stopping).\n",
    "\n",
    "model.save(PATH_MODEL + 'model.h5')  # save the model to file\n",
    "dump(mapping, open(PATH_MODEL + 'mapping.pkl', 'wb'))  # And save the mapping with which the text used for training was encoded (and it will be used for text to be used for predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, mapping, seed_text, n_chars, one_word=False):\n",
    "    \"\"\"\n",
    "    It uses the passed model and mapping to generate the indicated number of characters\n",
    "    :param model:       The model on which the predict method will be called\n",
    "    :param mapping:     The mapping to use for the sequence encoding\n",
    "    :param seed_text:   The test that will be completed\n",
    "    :param n_chars:     The desired length of the final sentence\n",
    "    :param one_word:    If True only complete the word and ignore seq_length (default: False)\n",
    "    :return:    The generated sequence\n",
    "    \"\"\"\n",
    "\n",
    "    seed_text = seed_text.lower()\n",
    "    return_text = seed_text\n",
    "    for _ in range(n_chars+SEQUENCE_LENGTH):  # The following block will be executed for the number of times indicated by n_chars, then until a sentence of this length (plus that of the seed_text) is formed\n",
    "        encoded = [mapping[char] for char in seed_text] # encode the characters as integers based on param mapping\n",
    "        encoded = pad_sequences([encoded], maxlen=SEQUENCE_LENGTH, truncating='pre')  # truncate sequences to length of SEQUENCE_LENGTH\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))  # Convert encoding numbers to one-hot vectors\n",
    "        pred_char = model.predict(encoded, verbose=0)  # The predict on the model is called to obtain the predicted character\n",
    "        #print(pred_char)\n",
    "        #print(tf.nn.softmax(pred_char))\n",
    "        #print(max(pred_char[0]))\n",
    "        #print(np.argmax(pred_char[0]))\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():  # The character corresponding to the one produced by the predict is searched in the mapping        \n",
    "            if index == np.argmax(pred_char[0]):\n",
    "                out_char = char\n",
    "                #print(\"index\", index, char)\n",
    "                break\n",
    "        seed_text += out_char  # The character thus obtained is added to the sequence that is being generated\n",
    "        return_text += out_char\n",
    "        if len(seed_text)>SEQUENCE_LENGTH:\n",
    "            seed_text = seed_text[len(seed_text)-SEQUENCE_LENGTH:]\n",
    "        if (one_word and out_char == ' ') or (len(return_text)>n_chars and out_char == ' '):  # If the one_word parameter was set to True and the predicted character is a space, the word has been completed\n",
    "            break  # And it stops\n",
    "\n",
    "        #print(seed_text) \n",
    "    return return_text  # The generated sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_text(text, model, mapping, one_word=False, length=SEQUENCE_LENGTH*2):\n",
    "    \"\"\"\n",
    "    A function that completes the passed text using the passed template and mapping\n",
    "    :param text: The test that will be completed\n",
    "    :param model: The model on which the predict will be called\n",
    "    :param mapping: The mapping to use for the sequence encoding\n",
    "    :param one_word: If set to True it will only complete the last word\n",
    "    :param length: The length of the final sentence (unless one_word = True parameter in which case the sentence could be shorter)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    text = preprocess_text(text)  # a minimal preprocessing.\n",
    "    if len(text) > SEQUENCE_LENGTH:  # If the proposed sentence is longer than SEQUENCE_LENGTH\n",
    "        text = text[(len(text)-SEQUENCE_LENGTH):len(text)]  # Part of the length of SEQUENCE_LENGTH will be taken\n",
    "    #if len(text) < SEQUENCE_LENGTH:  # If the proposed sentence is shorter than SEQUENCE_LENGTH\n",
    "    #    text = '             '[:(SEQUENCE_LENGTH - len(text))] + text  # spaces are added until the right length is reached\n",
    "    #    print('|' + text + '|')  # Print of the modified sentence\n",
    "    seq = generate_seq(model, mapping, text, length, one_word)  # The function that actually completed the sentence is called\n",
    "    print(seq)  # Print of the completed sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world \n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "complete_text('hello worl', model, mapping, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello works \n"
     ]
    }
   ],
   "source": [
    "complete_text('hello wo', model, mapping, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the works \n"
     ]
    }
   ],
   "source": [
    "complete_text('the w', model, mapping, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the works of the will of swedish industrialist \n"
     ]
    }
   ],
   "source": [
    "complete_text('The work', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whose works were published in the united \n"
     ]
    }
   ],
   "source": [
    "complete_text('Whose work', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this works the first fact ard industry , \n"
     ]
    }
   ],
   "source": [
    "complete_text('this work', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literah part of the religious writer john \n"
     ]
    }
   ],
   "source": [
    "complete_text('litera', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literaturan from soun 1011109 , ed . the \n"
     ]
    }
   ],
   "source": [
    "complete_text('literatu', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one such view is a process that continues \n"
     ]
    }
   ],
   "source": [
    "complete_text('One such view is', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accredited associated with academicoriented \n"
     ]
    }
   ],
   "source": [
    "complete_text('Accredited assoc', model, mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_complete_text(one_word=False, model=None, mapping=None):\n",
    "    \"\"\"\n",
    "    A test of the model consisting in ask for write some words with the last incomplete (or only the latter) verifying how the model completes it.\n",
    "    :param one_word: If set to True, the model will just complete the incomplete word, with False it will produce a 3x long sentence SEQUENCE_LENGTH.\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "    if model==None:\n",
    "        print(\"loading saved model...\")\n",
    "        model = load_model(PATH_MODEL + 'model.h5')  # Load model previously saved\n",
    "    if mapping==None:\n",
    "        print(\"loading saved mapping...\")\n",
    "        mapping = load(open(PATH_MODEL + 'mapping.pkl', 'rb'))  # And the mapping he was trained with\n",
    "\n",
    "    text = 'write a text'\n",
    "    while len(text) > 1:  # Keep repeating the following instructions until you reply with a return without writing anything\n",
    "        complete_text(text, model, mapping, one_word)  # The function that completes the passed sentence is called\n",
    "        text = input(\"Write a text, please...   \\n \")  # It invites you to write the sentence to complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_complete_text(model=model, mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello . prominent atheist figures such as the late christopher hitchens and richard dawkins have praised the king james version of the bible has been called the most influenthanks in advancelly invented drama : his oresteia trilogy of plays is seen as his crowning achievement . other refiners of playwriting were sophocles and euripides . sophocles is credited with skillfully developing irony as a literary technique , most famously in his play oedipus rex . euripedes , conversely , used plays to challenge \n"
     ]
    }
   ],
   "source": [
    "complete_text('hello ', model, mapping, length=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continue_text(text, model, mapping, one_word=False, length=SEQUENCE_LENGTH*2):\n",
    "    seq = ''\n",
    "    tot = 0\n",
    "    while tot < length:\n",
    "        text = preprocess_text(text)  # a minimal preprocessing.\n",
    "        if len(text) > SEQUENCE_LENGTH:  # If the proposed sentence is longer than SEQUENCE_LENGTH\n",
    "            text = text[(len(text)-SEQUENCE_LENGTH):len(text)]  # Part of the length of SEQUENCE_LENGTH will be taken\n",
    "        seq = generate_seq(model, mapping, text, SEQUENCE_LENGTH*2, one_word)  # The function that actually completed the sentence is called\n",
    "        tot += len(seq)\n",
    "        print(seq[:len(seq) - (SEQUENCE_LENGTH//2)], end='') \n",
    "        text = seq[len(seq) - (SEQUENCE_LENGTH//2):]\n",
    "    print('') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello . prominent atheist figures such as the renaissance , the focus on 19 , 000 and 20 , 000 and 2018 , produced the most outstanding that the recest of the academy was not in any condition to credibly jougnes to several earlier works 1850 , which had been states and will have a centain contribution . the products of distant lands and cormedtated to the world betodition . the religious of th\n"
     ]
    }
   ],
   "source": [
    "continue_text('hello ', model, mapping, length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
